## æµ‹è¯•å·¥å…·å®‰è£…

1. å®‰è£…kubectl

   ```shell 
   # ç¬¬ä¸€æ­¥
   curl -LO "https://dl.k8s.io/release/$(curl -L -s https://dl.k8s.io/release/stable.txt)/bin/linux/amd64/kubectl"
   # ç¬¬äºŒæ­¥
   sudo install -o root -g root -m 0755 kubectl /usr/local/bin/kubectl
   # éªŒè¯ç‰ˆæœ¬å·
   kubectl version --client
   ```

2. å®‰è£…k3d

   å‚æ•° `https://k3d.io/stable/#releases`

## Kubernetes Components

The components of a Kubernetes cluster:

![image-20250815091851689](./images/image-20250815091851689.png)

## Pod

* Pods are the smallest deployable units of computing that you can create and manage in Kubernetes

* You don't need to run multiple containers to provide replication (for resilience or capacity)

* Restarting a container in a Pod should not be confused with restarting a Pod. A Pod is not a process, but an
  environment for running container(s). A Pod persists until it is deleted.

* Modifying the pod template or switching to a new pod template has no direct effect on the Pods that already exist.
  > åªä¼šæ ¹æ®æ–°çš„æ›´æ–°çš„æ¨¡æ¿é‡æ–°åˆ›å»ºä¸€ä¸ªpod

* The name of a Pod must be a valid DNS subdomain value, but this can produce unexpected results for the Pod hostname.
  For best compatibility, the name should follow the more restrictive rules for a DNS label
  
* `kubectl describe pod` å‘½ä»¤ã€‚å®ƒä¼šå‘Šè¯‰ä½  Pod å¯åŠ¨è¿‡ç¨‹ä¸­å‘ç”Ÿçš„è¯¦ç»†äº‹ä»¶è®°å½•ã€‚

* æ€ä¹ˆçŸ¥é“æˆ‘çš„podæœ‰æ²¡æœ‰å¯åŠ¨æˆåŠŸï¼Ÿ

  > 1. å®è§‚æ£€æŸ¥ï¼š`kubectl get pods`
  > 2. è¯¦ç»†è¯Šæ–­ï¼š`kubectl describe pod [pod-name]`
  > 3. æ·±å…¥åº”ç”¨å†…éƒ¨ï¼š`kubectl logs [pod-name]` ã€å¯ä»¥ç”¨--previousé€‰æ‹©æ¥æŸ¥çœ‹ä¸Šä¸€æ¬¡çš„æ—¥å¿—ï¼Œè¿˜å¯ä»¥ç”¨-fã€‘


* ç¡®è®¤ Pod å†…çš„åº”ç”¨æ˜¯å¦çœŸçš„æ­£å¸¸å·¥ä½œ

  > è¿è¡Œä»¥ä¸‹å‘½ä»¤ï¼Œå®ƒä¼šåœ¨ä½ çš„æœ¬åœ° `8084` ç«¯å£å’Œ Deployment ä¸­çš„ä¸€ä¸ª Pod çš„ `8084` ç«¯å£ä¹‹é—´å»ºç«‹ä¸€ä¸ªä¸´æ—¶çš„ã€ç›´æ¥çš„é€šé“ï¼š
  >
  > ```shell
  > kubectl port-forward deployment/springboot3-deployment 8084:8084
  > ```
  >
  > > åœ¨ä½ çš„**æœ¬åœ°è®¡ç®—æœº**å’Œé›†ç¾¤å†…çš„ **Pod** ä¹‹é—´ï¼Œé€šè¿‡ Kubernetes API Server å»ºç«‹äº†ä¸€æ¡**ä¸´æ—¶çš„ã€åŠ å¯†çš„ã€ç‚¹å¯¹ç‚¹çš„é€šä¿¡éš§é“**ã€‚
  > >
  > > **æ²¡æœ‰è´Ÿè½½å‡è¡¡**ï¼š`port-forward` ä¸ä¼šåœ¨å¤šä¸ªå‰¯æœ¬ï¼ˆreplicasï¼‰ä¹‹é—´è½®è¯¢æˆ–åˆ†å‘æµé‡ã€‚æ‰€æœ‰è¯·æ±‚éƒ½ä¼šè¢«é€åˆ°åŒä¸€ä¸ª Pod å®ä¾‹ä¸Šã€‚
  > >
  > > **ä¼šè¯æ˜¯â€œç²˜æ€§â€çš„**ï¼šåœ¨ä½ æŒ‰ä¸‹ `Ctrl+C` ç»“æŸ `port-forward` å‘½ä»¤ä¹‹å‰ï¼Œè¿™ä¸ªéš§é“ä¼šä¸€ç›´è¿æ¥åˆ°æœ€åˆé€‰å®šçš„é‚£ä¸ª Podã€‚
  > >
  > > **æ²¡æœ‰è‡ªåŠ¨æ•…éšœè½¬ç§»**ï¼šå¦‚æœåœ¨ `port-forward` è¿è¡ŒæœŸé—´ï¼Œå®ƒè¿æ¥çš„é‚£ä¸ª Pod æ°å¥½â€œåäº†â€å¹¶è¢« Kubernetes é‡å¯ï¼Œä½ çš„ `port-forward` è¿æ¥ä¼š**ä¸­æ–­**ï¼Œå‘½ä»¤ä¼šæŠ¥é”™å¹¶é€€å‡ºã€‚
  >
  > è¿˜å¯ä»¥åœ¨åœ¨é›†ç¾¤å†…éƒ¨æµ‹è¯• ï¼š
  >
  > **å¯åŠ¨ä¸€ä¸ªä¸´æ—¶çš„æµ‹è¯• Pod**ï¼šæˆ‘ä»¬å¯ä»¥è¿è¡Œä¸€ä¸ªåŒ…å« `curl` ç­‰ç½‘ç»œå·¥å…·çš„ä¸´æ—¶ Podã€‚
  >
  > ```shell
  > # è¿è¡Œä¸€ä¸ªä¸´æ—¶çš„ busybox Podï¼Œå¹¶åœ¨ç»“æŸåè‡ªåŠ¨åˆ é™¤
  > kubectl run my-test-pod --image=busybox -it --rm -- sh
  > ## kubectl run my-debug-pod --image=curlimages/curl -i --tty --rm -- /bin/sh è¿™ä¸ªä¹Ÿå¯ä»¥
  > ```
  >
  > **åœ¨ä¸´æ—¶ Pod å†…é€šè¿‡ Service åç§°è®¿é—®**ï¼šKubernetes è‡ªå¸¦äº† DNS æœåŠ¡ï¼Œä½ å¯ä»¥ç›´æ¥é€šè¿‡ Service çš„åç§°æ¥è®¿é—®å®ƒã€‚
  >
  > ```shell
  > # å‡è®¾ä½ å·²ç»åœ¨ my-test-pod çš„ shell ä¸­
  > # è¯­æ³•: wget -qO- http://[service-name]:[service-port]
  > wget -qO- http://springboot3-service:80
  > ```
  >
  > å¦‚æœè¿”å›äº†åº”ç”¨çš„æ­£ç¡®å“åº”ï¼Œè¯´æ˜ Service çš„æœåŠ¡å‘ç°å’Œç«¯å£è½¬å‘éƒ½æ˜¯æ­£å¸¸çš„ã€‚

* ä»€ä¹ˆæ—¶å€™ä¼šå•ç‹¬å®šä¹‰å’Œä½¿ç”¨ Pod

  > **åœºæ™¯ç¤ºä¾‹**ï¼šä½ æƒ³æµ‹è¯•ä¸€ä¸‹é›†ç¾¤å†…éƒ¨çš„ç½‘ç»œæ˜¯å¦é€šç•…ï¼Œæˆ–è€…æƒ³çœ‹æŸä¸ª `Service` æ˜¯å¦èƒ½è¢«è®¿é—®åˆ°ã€‚
  >
  > **æ“ä½œ**ï¼šä½ å¯ä»¥å¿«é€Ÿåˆ›å»ºä¸€ä¸ªåŒ…å«ç½‘ç»œå·¥å…·ï¼ˆå¦‚ `curl`, `ping`, `dig`ï¼‰çš„ Podï¼Œç„¶åé€šè¿‡ `kubectl exec` è¿›å…¥è¿™ä¸ª Pod è¿›è¡Œè°ƒè¯•ã€‚è°ƒè¯•ç»“æŸåï¼Œç›´æ¥åˆ é™¤è¿™ä¸ª Pod å³å¯ï¼Œä¸ç•™ä»»ä½•ç—•è¿¹ã€‚
  >
  > **ç¤ºä¾‹ YAML (**`debug-pod.yaml`**)ï¼š**
  >
  > ```yaml
  > apiVersion: v1
  > kind: Pod
  > metadata:
  > name: curl-pod
  > spec:
  >  containers:
  >       - name: my-curl # æˆ‘ä»¬ç”¨ä¸€ä¸ªåŒ…å« curl çš„é•œåƒï¼Œå¹¶è®©å®ƒä¸€ç›´è¿è¡Œï¼Œä»¥ä¾¿æˆ‘ä»¬èƒ½ exec è¿›å»
  >         image: curlimages/curl:latest
  >     command: ["sleep", "3600"] # è®©å®¹å™¨ä¿æŒè¿è¡Œï¼Œå¦åˆ™å®ƒä¼šç«‹å³é€€å‡º
  > ```
  >
  > **ä½¿ç”¨å‘½ä»¤**:
  >
  >   ```shell
  >   # åˆ›å»º Pod
  >   kubectl apply -f debug-pod.yaml
  > 
  >   # è¿›å…¥ Pod å†…éƒ¨æ‰§è¡Œå‘½ä»¤
  >   kubectl exec -it curl-pod -- sh
  > 
  >   # (åœ¨ Pod å†…éƒ¨)
  >   # curl [your-service-name].[namespace].svc.cluster.local
  >   # exit
  > 
  >   # è°ƒè¯•å®Œæ¯•ååˆ é™¤ Pod
  >   kubectl delete pod curl-pod 
  >   ```

* Pods that are part of a DaemonSet tolerate being run on an unschedulable Node. DaemonSets typically provide node-local
  services that should run on the Node even if it is being drained of workload applications.

  > åœ¨ Kubernetes ä¸­ï¼Œè¿™äº›â€œå¿…é¡»å®‰è£…åœ¨æ¯ä¸ªèŠ‚ç‚¹ä¸Šâ€çš„åå°æœåŠ¡ï¼Œå°±æ˜¯é€šè¿‡ DaemonSet æ¥éƒ¨ç½²çš„ã€‚å¸¸è§çš„ä¾‹å­æœ‰ï¼šæ—¥å¿—æ”¶é›†å™¨ï¼ŒèŠ‚ç‚¹ç›‘æ§å™¨ï¼Œç½‘ç»œæ’ä»¶ï¼Œå­˜å‚¨æ’ä»¶

##  Deployment

* Deploymentï¼šè´Ÿè´£ç®¡ç†å’Œç»´æŠ¤ä½ çš„åº”ç”¨å®ä¾‹ï¼ˆPodï¼‰ã€‚å®ƒä¼šç¡®ä¿æŒ‡å®šæ•°é‡çš„ Nginx Pod æ­£åœ¨è¿è¡Œã€‚å¦‚æœæŸä¸ª Pod æŒ‚æ‰äº†ï¼ŒDeployment
  ä¼šè‡ªåŠ¨åˆ›å»ºä¸€ä¸ªæ–°çš„æ¥æ›¿ä»£å®ƒ
* åœ¨ Deploymentï¼ˆä»¥åŠ ReplicaSet, StatefulSet, Job, CronJob ç­‰è¿™ç±»æ§åˆ¶å™¨ï¼‰çš„ Pod æ¨¡æ¿ï¼ˆspec.templateï¼‰ä¸­ï¼Œmetadata.name è¿™ä¸ªå­—æ®µæ˜¯ä¸èƒ½è®¾ç½®çš„ã€‚å¦‚æœä½ å°è¯•è®¾ç½®å®ƒï¼ŒKubernetes API Server ä¼šæ‹’ç»ä½ çš„è¯·æ±‚ã€‚
* Deployment è¦èƒ½å¤Ÿæ­£å¸¸å·¥ä½œï¼ˆç‰¹åˆ«æ˜¯è¿è¡Œå¤šä¸ªå‰¯æœ¬ã€è¿›è¡Œæ»šåŠ¨æ›´æ–°å’Œè‡ªæˆ‘ä¿®å¤ï¼‰ï¼Œå…¶åº•å±‚çš„ Pod å¿…é¡»é€šè¿‡ç±»ä¼¼ `generateName` çš„æœºåˆ¶æ¥åˆ›å»ºï¼Œä»¥ä¿è¯æ¯ä¸ª Pod åç§°çš„å”¯ä¸€æ€§
* The server may generate a name when generateName is provided instead of name in a resource create request. When generateName is used, the provided value is used as a name prefix, which server appends a generated suffix to.

  > Kubernetes v1.31ä»¥åä¼šé‡è¯•8æ¬¡ä»¥ä½¿ç”Ÿæˆå”¯ä¸€çš„åå­—
* åœ¨ Deploymentï¼ˆä»¥åŠ ReplicaSet, StatefulSet, Job, CronJob ç­‰è¿™ç±»æ§åˆ¶å™¨ï¼‰çš„ Pod æ¨¡æ¿ï¼ˆ`spec.template`ï¼‰ä¸­ï¼Œ`metadata.name` è¿™ä¸ªå­—æ®µæ˜¯**ä¸èƒ½è®¾ç½®**çš„ã€‚å¦‚æœä½ å°è¯•è®¾ç½®å®ƒï¼ŒKubernetes API Server ä¼šæ‹’ç»ä½ çš„è¯·æ±‚ã€‚

* ä¸€ä¸ª Deployment å®é™…ä¸Šå¹¶ä¸ç›´æ¥ç®¡ç† Podï¼Œå®ƒçš„å·¥ä½œæµç¨‹æ˜¯è¿™æ ·çš„ï¼š

  1. **Deployment**: ä½ åˆ›å»ºäº†ä¸€ä¸ª Deployment èµ„æºï¼Œå®ƒçš„åç§°æ˜¯å›ºå®šçš„ï¼ˆæ¯”å¦‚ `nginx-deployment`ï¼‰ã€‚è¿™ä¸ª Deployment è´Ÿè´£ç®¡ç†â€œç‰ˆæœ¬â€ã€‚
  2. **ReplicaSet**: Deployment ä¼šæ ¹æ®è‡ªå·±çš„ Pod æ¨¡æ¿ï¼Œåˆ›å»ºä¸€ä¸ª **ReplicaSet** èµ„æºã€‚è¿™ä¸ª ReplicaSet çš„åç§°æ˜¯**åŠ¨æ€ç”Ÿæˆçš„**ï¼Œé€šå¸¸æ˜¯ `[Deploymentåç§°]-[Podæ¨¡æ¿çš„å“ˆå¸Œå€¼]`ï¼Œä¾‹å¦‚ `nginx-deployment-66b6c48dd5`ã€‚è¿™ä¸ªå“ˆå¸Œå€¼ç¡®ä¿äº†æ¯æ¬¡ä½ æ›´æ–° Deployment çš„ Pod æ¨¡æ¿æ—¶ï¼ˆæ¯”å¦‚æ›´æ¢é•œåƒç‰ˆæœ¬ï¼‰ï¼Œéƒ½ä¼šåˆ›å»ºä¸€ä¸ªå…¨æ–°çš„ã€ä¸åŒåç§°çš„ ReplicaSetã€‚
  3. **Pod**: ReplicaSet çš„ä»»åŠ¡å¾ˆç®€å•ï¼Œå°±æ˜¯ç¡®ä¿æœ‰æŒ‡å®šæ•°é‡çš„ã€ç¬¦åˆå…¶æ¨¡æ¿çš„ Pod æ­£åœ¨è¿è¡Œã€‚å®ƒä¼šæ ¹æ®è‡ªå·±çš„åç§°ä½œä¸º**å‰ç¼€**ï¼Œå»åˆ›å»º Podã€‚æ‰€ä»¥ï¼Œæœ€ç»ˆ Pod çš„åç§°ä¹Ÿæ˜¯**åŠ¨æ€ç”Ÿæˆçš„**ï¼Œæ ¼å¼é€šå¸¸æ˜¯ `[ReplicaSetåç§°]-[éšæœºåç¼€]`ï¼Œä¾‹å¦‚ `nginx-deployment-66b6c48dd5-x7p9m`ã€‚

## Servcie

* Serviceï¼šè´Ÿè´£ä¸ºä¸€ç»„ Pod æä¾›ä¸€ä¸ªç¨³å®šã€ç»Ÿä¸€çš„è®¿é—®å…¥å£ã€‚å› ä¸º Pod æ˜¯â€œçŸ­æš‚â€çš„ï¼Œå®ƒä»¬çš„ IP åœ°å€ä¼šå˜åŒ–ã€‚Service æä¾›äº†ä¸€ä¸ªå›ºå®šçš„
  IP åœ°å€å’Œ DNS åç§°ï¼Œä½¿å¾—å…¶ä»–åº”ç”¨æˆ–å¤–éƒ¨ç”¨æˆ·å¯ä»¥æ–¹ä¾¿åœ°è®¿é—®åˆ°ä½ çš„ Nginx æœåŠ¡ï¼Œè€Œæ— éœ€å…³å¿ƒåç«¯å…·ä½“æ˜¯å“ªä¸ª Pod åœ¨æä¾›æœåŠ¡ã€‚

  > Service çš„ IP åœ°å€ (`ClusterIP`) å’Œ DNS åç§°çš„â€œå›ºå®šâ€ï¼Œæ˜¯ç›¸å¯¹äº **Service è¿™ä¸ª API å¯¹è±¡çš„ç”Ÿå‘½å‘¨æœŸ** è€Œè¨€çš„ã€‚
  >
  > ç®€å•æ¥è¯´ï¼Œåªè¦ä½ ä¸åˆ é™¤è¿™ä¸ª Service å¯¹è±¡ï¼ˆ`kubectl delete service my-service`ï¼‰ï¼Œå®ƒçš„ `ClusterIP` å’Œ DNS åç§°å°±**ä¸ä¼šæ”¹å˜**ã€‚
  >
  >  FQDN (Fully Qualified Domain Name)ï¼š [service-name].[namespace-name].svc.[cluster-domain].
  >
  > * `[cluster-domain]` é›†ç¾¤åŸŸåæ˜¯é›†ç¾¤çº§åˆ«çš„é…ç½®ï¼Œé€šå¸¸æ˜¯å›ºå®šçš„ã€‚æœ€å¯é çš„æŸ¥æ‰¾æ–¹æ³•æ˜¯è¿›å…¥ä»»æ„ä¸€ä¸ªæ­£åœ¨è¿è¡Œçš„ Podï¼ŒæŸ¥çœ‹å®ƒçš„ DNS é…ç½®æ–‡ä»¶ `/etc/resolv.conf`
  >
  >   ```shell
  >   # 1. é¦–å…ˆï¼Œéšä¾¿æ‰¾ä¸€ä¸ªæ­£åœ¨è¿è¡Œçš„ Pod
  >   kubectl get pods
  >   
  >   # å‡è®¾æˆ‘ä»¬æ‰¾åˆ°äº†ä¸€ä¸ªå« nginx-deployment-6bcfd6f857-klmno çš„ Pod
  >   
  >   # 2. ä½¿ç”¨ kubectl exec è¿›å…¥è¯¥ Pod å¹¶æŸ¥çœ‹ resolv.conf æ–‡ä»¶
  >   kubectl exec -it nginx-deployment-6bcfd6f857-klmno -- cat /etc/resolv.conf
  >   ## åœ¨ä¸Šé¢è¿™ä¸ªå‘½ä»¤ä¸­ï¼Œcat å‰é¢çš„`--` èµ·åˆ°åˆ†éš”çš„ä½œç”¨ï¼Œå‘Šè¯‰kubectlçš„å‘½ä»¤å·²ç»ç»“æŸã€‚ä¸docker execä¸åŒï¼Œdocker exec ä¸éœ€è¦è¿™ä¸ª                                   
  >   ```
  >
  >   è¾“å‡ºä¸­`search default.svc.cluster.local svc.cluster.local cluster.local`  æœ€åè¿™ä¸ª`cluster.local` å°±æ˜¯è¿™ä¸ªå€¼
  >
  > * è¿˜å¯ä»¥åœ¨é›†ç¾¤å†…ç›´æ¥æŸ¥è¯¢
  >
  >   å¯åŠ¨ä¸€ä¸ªä¸´æ—¶çš„è°ƒè¯• Pod
  >
  >   ```shell
  >   # è¿è¡Œä¸€ä¸ªä¸´æ—¶çš„ busybox Podï¼Œå¹¶è¿›å…¥å…¶ shell ç¯å¢ƒ
  >   kubectl run dns-test -it --rm --image=busybox:1.28 -- sh
  >   ```
  >
  >   åœ¨ Pod å†…éƒ¨ä½¿ç”¨ `nslookup` è¿›è¡ŒæŸ¥è¯¢
  >
  >   ```shell
  >   # (å› ä¸ºæˆ‘ä»¬åœ¨ default å‘½åç©ºé—´é‡Œ)
  >   nslookup springboot3-service
  >   ```

* ä½ å¯ä»¥æŠŠ app: nginx ç†è§£ä¸ºä½ å’Œ Kubernetes çš„ä¸€ä¸ªçº¦å®šï¼šä½ ç»™ä¸€ç»„ Pod è´´ä¸Šè¿™ä¸ªç‹¬ç‰¹çš„â€œåç‰Œâ€ï¼Œç„¶åå‘Šè¯‰ Deployment å’Œ Service
  æŒ‰ç…§è¿™ä¸ªâ€œåç‰Œâ€å»è®¤é¢†å’ŒæŸ¥æ‰¾å®ƒä»¬
  
* Service `type` æ˜¯ `ClusterIP`ã€é»˜è®¤å€¼ã€‘æ—¶ipä¸ç›´æ¥æš´éœ²åˆ°é›†ç¾¤å¤–éƒ¨ï¼Œåªèƒ½è¢«é›†ç¾¤å†…çš„ Ingress æ§åˆ¶å™¨æ‰¾åˆ°ã€‚typeä¸ºloadBalanceræ—¶, ç«¯å£ä¼šæš´éœ²åˆ°é›†ç¾¤å¤–ã€‚ã€åœ¨k3dä¸­æµ‹è¯•æ—¶ï¼ŒæŠŠserviceçš„typeè®¾ç½®ä¸ºloadBalanceå¹¶ä¸ç”Ÿæ•ˆã€‘
  
  > `LoadBalancer` ç±»å‹æ˜¯ `NodePort` çš„æ‰©å±•ã€‚å®ƒä¼šå‘åº•å±‚äº‘å¹³å°ï¼ˆå¦‚ AWS, GCP, Azureï¼‰è¯·æ±‚ä¸€ä¸ªå¤–éƒ¨è´Ÿè½½å‡è¡¡å™¨ï¼Œå¹¶å°†è¿™ä¸ªè´Ÿè½½å‡è¡¡å™¨çš„ IP åœ°å€ä½œä¸º Service çš„å¤–éƒ¨è®¿é—®å…¥å£ã€‚
  >
  > - **ä½œç”¨**ï¼šè¿™æ˜¯å°†æœåŠ¡æš´éœ²åˆ°å…¬ç½‘çš„ **æ ‡å‡†æ–¹å¼**ã€‚äº‘æœåŠ¡æä¾›å•†ä¼šä¸ºä½ åˆ›å»ºä¸€ä¸ªè´Ÿè½½å‡è¡¡å™¨ï¼Œå¹¶å°†æµé‡å¯¼å‘ä½ æ‰€æœ‰èŠ‚ç‚¹çš„ `NodePort`ã€‚
  > - **ä½¿ç”¨åœºæ™¯**ï¼šé€‚ç”¨äºç”Ÿäº§ç¯å¢ƒï¼Œå½“ä½ éœ€è¦ä¸€ä¸ªç¨³å®šã€é«˜å¯ç”¨çš„å…¬ç½‘ IP æ¥æš´éœ²ä½ çš„æœåŠ¡æ—¶ã€‚

## Config file

* kubectl é»˜è®¤ä¼šåœ¨ä½ çš„ç”¨æˆ·ä¸»ç›®å½•ä¸‹çš„ .kube æ–‡ä»¶å¤¹ä¸­å¯»æ‰¾åä¸º config çš„æ–‡ä»¶ã€‚

  > åœ¨ Linux å’Œ macOS ä¸Šï¼Œè·¯å¾„é€šå¸¸æ˜¯ ~/.kube/configã€‚

* Most often, you provide the information to kubectl in a file known as a manifest. By convention, manifests are YAML (you could also use JSON format).

* YAML æ–‡ä»¶åœ¨ä¸¤ç§æ¨¡å¼ä¸‹çš„â€œè§’è‰²â€
    * åœ¨ kubectl create -f (å‘½ä»¤å¼) ä¸­ï¼šYAML æ–‡ä»¶æ˜¯ä¸€ä¸ªä¸€æ¬¡æ€§çš„æ¨¡æ¿ã€‚ä½ å‘½ä»¤ Kubernetesï¼šâ€œæŒ‰ç…§è¿™ä¸ªæ¨¡æ¿ï¼Œç»™æˆ‘åˆ›å»ºä¸€ä¸ªå¯¹è±¡â€ã€‚åˆ›å»ºå®Œæˆåï¼Œè¿™ä¸ª
      YAML æ–‡ä»¶å’Œé›†ç¾¤ä¸­çš„é‚£ä¸ªå¯¹è±¡ä¹‹é—´ï¼Œå°±æ²¡æœ‰å¿…ç„¶çš„è”ç³»äº†ã€‚Kubernetes ä¸ä¼šâ€œè®°ä½â€ä½ æ˜¯ç”¨å“ªä¸ªæ–‡ä»¶åˆ›å»ºçš„å®ƒã€‚
    * åœ¨ kubectl apply -f (å£°æ˜å¼) ä¸­ï¼šYAML æ–‡ä»¶æ˜¯å¯¹è±¡çš„**â€œæœŸæœ›çŠ¶æ€â€çš„å£°æ˜**ã€‚ä½ å‘Šè¯‰ Kubernetesï¼šâ€œè¯·ç¡®ä¿é›†ç¾¤ä¸­æœ‰ä¸€ä¸ªä¸è¿™ä¸ª
      YAML æ–‡ä»¶æè¿°çš„çŠ¶æ€ç›¸åŒ¹é…çš„å¯¹è±¡â€ã€‚Kubernetes ä¸ä»…ä¼šåˆ›å»ºè¿™ä¸ªå¯¹è±¡ï¼Œè¿˜ä¼šè®°å½•ä¸‹è¿™ä¸ªâ€œæœŸæœ›çŠ¶æ€â€ï¼Œä»¥ä¾¿äºæœªæ¥çš„æ¯”è¾ƒå’Œæ›´æ–°ã€‚

* ä»…ä»…ä¿®æ”¹å¹¶ä¿å­˜åœ¨æœ¬åœ° configs/ ç›®å½•ä¸‹çš„ YAML æ–‡ä»¶ï¼Œå¹¶ä¸ä¼šå¯¹é›†ç¾¤äº§ç”Ÿä»»ä½•å½±å“ã€‚ Kubernetes é›†ç¾¤å®Œå…¨ä¸çŸ¥é“ä½ æœ¬åœ°æ–‡ä»¶çš„å˜åŒ–ã€‚ä½ å¿…é¡»é€šè¿‡
  kubectl apply è¿™ä¸ªåŠ¨ä½œï¼Œæ˜ç¡®åœ°å‘Šè¯‰ Kubernetesï¼šâ€œè¯·æŒ‰ç…§æˆ‘æœ€æ–°çš„é…ç½®æ–‡ä»¶ï¼Œå»åŒæ­¥é›†ç¾¤çš„çŠ¶æ€ã€‚â€

* ä»…ä»…ä¿®æ”¹å¹¶ä¿å­˜åœ¨æœ¬åœ° configs/ ç›®å½•ä¸‹çš„ YAML æ–‡ä»¶ï¼Œå¹¶ä¸ä¼šå¯¹é›†ç¾¤äº§ç”Ÿä»»ä½•å½±å“ã€‚ Kubernetes é›†ç¾¤å®Œå…¨ä¸çŸ¥é“ä½ æœ¬åœ°æ–‡ä»¶çš„å˜åŒ–ã€‚ä½ å¿…é¡»é€šè¿‡
  kubectl apply è¿™ä¸ªåŠ¨ä½œï¼Œæ˜ç¡®åœ°å‘Šè¯‰ Kubernetesï¼šâ€œè¯·æŒ‰ç…§æˆ‘æœ€æ–°çš„é…ç½®æ–‡ä»¶ï¼Œå»åŒæ­¥é›†ç¾¤çš„çŠ¶æ€ã€‚â€

  ```shell
   kubectl diff -f configs/
  ```

  Our previous example (replicas): The change from kubectl scale was NOT retained because the replicas field was "owned"
  by your YAML file. apply enforced your file's value.

* The note's meaning (LoadBalancer example): Changes from other controllers (like adding a clusterIP) ARE retained, because those fields are not "owned" by your YAML file. The patch mechanism surgically updates only the fields you explicitly manage in your file.

* Starting with Kubernetes v1.25, the API server offers server side field validation that detects unrecognized or duplicate fields in an object. It provides all the functionality of kubectl --validate on the server side.

  > **æœåŠ¡ç«¯è¯•è¿è¡Œ (Server-side Dry Run)**
  >
  > ```shell
  > kubectl apply -f [your-manifest].yaml --dry-run=server
  > ```
  >
  > å¦‚æœæ–‡ä»¶æœ‰é”™è¯¯ï¼Œå®ƒä¼šåƒä¸Šé¢çš„ä¾‹å­ä¸€æ ·æŠ¥é”™ã€‚å¦‚æœæ–‡ä»¶æ ¼å¼æ­£ç¡®ï¼Œå®ƒä¼šè¿”å›ä¸€ä¸ªæˆåŠŸçš„æç¤ºï¼ˆä½†ä¸ä¼šçœŸçš„åˆ›å»ºèµ„æºï¼‰ã€‚**æ€»ä¹‹ï¼Œ--dry-run=server æ˜¯ä¸€ä¸ªéå¸¸å®‰å…¨çš„éªŒè¯å·¥å…·ã€‚** å®ƒçš„è®¾è®¡åˆè¡·å°±æ˜¯ä¸ºäº†è®©æ‚¨åœ¨çœŸæ­£éƒ¨ç½²åˆ°é›†ç¾¤ä¹‹å‰ï¼Œç™¾åˆ†ä¹‹ç™¾ç¡®è®¤æ‚¨çš„é…ç½®æ¸…å•æ˜¯æœ‰æ•ˆä¸”è¢«é›†ç¾¤æ‰€æ¥å—çš„ï¼Œè€Œæ— éœ€æ‹…å¿ƒä¼šæ„å¤–åˆ›å»ºæˆ–ä¿®æ”¹ä»»ä½•ä¸œè¥¿ã€‚

## Object

Kubernetes objects are persistent entities in the Kubernetes system. Kubernetes uses these entities to represent the state of your cluster. Learn about the Kubernetes object model and how to work with these objects.

* Keep in mind that label Key must be unique for a given object
  
* Names of resources need to be unique within a namespace, but not across namespaces.
  
* When you create an object in Kubernetes, you must provide the object spec that describes its desired state, as well as
  some basic information about the object (such as a name).

* Almost every Kubernetes object includes two nested object fields that govern the object's configuration: the object spec and the object status.

* The status describes the current state of the object, supplied and updated by the Kubernetes system and its components.

  > statuså¯ä»¥ç†è§£ä¸ºâ€œçœ‹èµ·æ¥æ˜¯ä»€ä¹ˆæ ·â€ï¼Œè€Œstateæ˜¯â€œå®é™…æ˜¯ä»€ä¹ˆæ ·å­çš„â€

* Each object in your cluster has a Name that is unique for that type of resource. Every Kubernetes object also has a UID that is unique across your whole cluster.

  > For example, you can only have one Pod named `myapp-1234` within the same namespace, but you can have one Pod and one Deployment that are each named `myapp-1234`.

* **Kubernetes çš„ä¸–ç•Œè§‚æ˜¯å»ºç«‹åœ¨å®ƒè‡ªå·±çš„ API å¯¹è±¡ä¸Šçš„**ã€‚å®ƒé€šè¿‡ Kubelet ç­‰ç»„ä»¶æ¥è§‚æµ‹å¤–éƒ¨ç‰©ç†ä¸–ç•Œçš„çŠ¶æ€ï¼Œå¹¶å°½åŠ›ä½¿å…¶ä¸å†…éƒ¨çš„å£°æ˜å¼çŠ¶æ€ä¿æŒä¸€è‡´ã€‚ä½†å¦‚æœå¤–éƒ¨ä¸–ç•Œå‘ç”Ÿäº†å®ƒæ— æ³•è§‚æµ‹åˆ°çš„å‰§çƒˆå˜åŒ–ï¼ˆæ¯”å¦‚ä¸€ä¸ªèŠ‚ç‚¹è¢«å·å·æ›¿æ¢äº†ï¼‰ï¼Œè€Œå†…éƒ¨çš„é€»è¾‘å¯¹è±¡æ²¡æœ‰è¢«ç›¸åº”æ›´æ–°ï¼Œå°±ä¼šå¯¼è‡´è¿™ç§â€œèº«ä»½æ··æ·†â€å’ŒçŠ¶æ€ä¸ä¸€è‡´ï¼Œä»è€Œå¼•å‘å„ç§éš¾ä»¥æ’æŸ¥çš„è¯¡å¼‚é—®é¢˜ã€‚

  > åœ¨ç‰©ç†/è™šæ‹Ÿå±‚é¢é”€æ¯ä¸€ä¸ªèŠ‚ç‚¹ä¹‹å‰ï¼Œ**åŠ¡å¿…å…ˆåœ¨ Kubernetes ä¸­å°†å…¶åˆ é™¤**ã€‚
  >
  > æ­£ç¡®çš„æ“ä½œæµç¨‹åº”è¯¥æ˜¯ï¼š
  >
  > 1. **æ ‡è®°èŠ‚ç‚¹ä¸å¯è°ƒåº¦**ï¼š
  >
  >    ```shell
  >    kubectl cordon worker-01
  >    ```
  >
  >    è¿™èƒ½é˜²æ­¢æ–°çš„ Pod è¢«è°ƒåº¦åˆ°è¯¥èŠ‚ç‚¹ä¸Šã€‚
  >
  > 2. **é©±é€èŠ‚ç‚¹ä¸Šçš„æ‰€æœ‰ Pod**ï¼š
  >
  >    ```shell
  >    kubectl drain worker-01 --ignore-daemonsets
  >    ```
  >
  >    è¿™ä¼šå®‰å…¨åœ°å°†è¯¥èŠ‚ç‚¹ä¸Šç°æœ‰çš„ Pod è¿ç§»åˆ°å…¶ä»–èŠ‚ç‚¹ã€‚`--ignore-daemonsets` æ˜¯å› ä¸º DaemonSet ç®¡ç†çš„ Pod ä¸éœ€è¦è¢«é©±é€ã€‚
  >
  > 3. **ä» Kubernetes ä¸­åˆ é™¤èŠ‚ç‚¹å¯¹è±¡**ï¼š
  >
  >    ```shell
  >    kubectl delete node worker-01
  >    ```
  >
  >    è¿™ä¸€æ­¥å°±æ˜¯â€œé”€æ¯å­¦ç±å¡â€ï¼Œå½»åº•æ¸…é™¤å®ƒåœ¨ Kubernetes ä¸­çš„æ‰€æœ‰è®°å½•ã€‚
  >
  > 4. **é”€æ¯ç‰©ç†/è™šæ‹Ÿæœº**ï¼š ç°åœ¨ï¼Œä½ å¯ä»¥å®‰å…¨åœ°å»ä½ çš„äº‘å¹³å°æˆ–è™šæ‹ŸåŒ–å¹³å°åˆ é™¤è¿™å°æœåŠ¡å™¨äº†ã€‚

* A client-provided string that refers to an object in a [resource](https://kubernetes.io/docs/reference/using-api/api-concepts/#standard-api-terminology) URL, such as `/api/v1/pods/some-name`.

  Only one object of a given kind can have a given name at a time.  Names must be unique across **all API versions** of the same resource. API resources are distinguished by their API group, resource type, namespace (for namespaced resources), and name. In other words, API version is irrelevant in this context.

* In cases when objects represent a physical entity, like a Node representing a physical host, when the host is re-created under the same name without deleting and re-creating the Node, Kubernetes treats the new host as the old one, which may lead to inconsistencies.

  > 1. æ ‡è®°èŠ‚ç‚¹ä¸å¯è°ƒåº¦
  >
  >    kubectl cordon worker-01
  >
  > 2. **é©±é€èŠ‚ç‚¹ä¸Šçš„æ‰€æœ‰ Pod**
  >
  >    kubectl drain worker-01 --ignore-daemonsets
  >
  > 3. ä» Kubernetes ä¸­åˆ é™¤èŠ‚ç‚¹å¯¹è±¡
  >
  >    kubectl delete node worker-01

## Kubernetes API 

* There are two mechanisms that Kubernetes uses to publish these API specifications

  > 1. The Discovery API
  > 2. The Kubernetes OpenAPI Document

* é¦–å…ˆï¼Œæˆ‘ä»¬å¿…é¡»æ˜ç™½ Discovery API çš„ç›®çš„ã€‚æ— è®ºæ˜¯ kubectlã€Rancher UI è¿˜æ˜¯ä»»ä½•å…¶ä»–ä¸ Kubernetes é›†ç¾¤äº¤äº’çš„å®¢æˆ·ç«¯ï¼Œå®ƒä»¬åœ¨æ‰§è¡Œæ“ä½œä¹‹å‰ï¼Œéƒ½éœ€è¦å…ˆçŸ¥é“ï¼š
  
  * â€œè¿™ä¸ªé›†ç¾¤é‡Œæœ‰å“ªäº› API Groupï¼Ÿâ€: (ä¾‹å¦‚ apps, batch, networking.k8s.io ç­‰)ã€‚
  * â€œæ¯ä¸ª Group ä¸‹æœ‰å“ªäº›ç‰ˆæœ¬ï¼Ÿâ€ : (ä¾‹å¦‚ apps group ä¸‹æœ‰v1)â€œ
  * æ¯ä¸ª Group/Version ä¸‹æœ‰å“ªäº›èµ„æº (Resource)ï¼Ÿâ€ : (ä¾‹å¦‚ apps/v1 ä¸‹æœ‰ deployments, statefulsets, daemonsets ç­‰)
  * â€œè¿™äº›èµ„æºæ”¯æŒå“ªäº›æ“ä½œ (Verb)ï¼Ÿâ€ : (ä¾‹å¦‚ deployments æ”¯æŒ create, get, list, delete ç­‰)
  
* Unaggregated Discovery (éèšåˆå‘ç°)
  Unaggregated Discovery æŒ‡çš„æ˜¯ å•ä¸ª API æœåŠ¡å™¨è‡ªèº« æä¾›çš„ã€å…³äº å®ƒè‡ªå·±æ‰€èƒ½æœåŠ¡çš„ API çš„å‘ç°ä¿¡æ¯ã€‚

* Aggregated Discovery (èšåˆå‘ç°)
  Aggregated Discovery æ­£æ˜¯ Kubernetes API Aggregation Layer (èšåˆå±‚) çš„å¼ºå¤§ä¹‹å¤„ã€‚å®ƒæä¾›äº†ä¸€ä¸ª ç»Ÿä¸€çš„ã€èšåˆå çš„è§†å›¾ã€‚
  å½“å®¢æˆ·ç«¯ï¼ˆå¦‚ kubectlï¼‰æŸ¥è¯¢ä¸» kube-apiserver çš„å‘ç°ç«¯ç‚¹æ—¶ï¼Œèšåˆå±‚ä¸ä»…ä¼šè¿”å› kube-apiserver è‡ªå·±çš„ API ä¿¡æ¯ï¼Œè¿˜ä¼šæ™ºèƒ½åœ°å°†æ‰€æœ‰å·²æ³¨å†Œçš„æ‰©å±•
  API æœåŠ¡å™¨ï¼ˆé€šè¿‡ APIService å¯¹è±¡æ³¨å†Œï¼‰çš„å‘ç°ä¿¡æ¯ä¹Ÿä¸€å¹¶åŒ…å«è¿›æ¥å¹¶è¿”å›ã€‚
  
* Kubernetes offers stable support for aggregated discovery, publishing all resources supported by a cluster through two
  endpoints (/api and /apis).
  > * /api: åˆ—å‡ºæ ¸å¿ƒ API Group (åªæœ‰ v1)ã€‚ã€**æ ¸å¿ƒ API (Core API)** æˆ–ç§°ä¸º**å†å²é—ç•™ API (Legacy API)**ã€‘
  > * /apis: åˆ—å‡ºæ‰€æœ‰éæ ¸å¿ƒçš„ API Group (å¦‚ apps, batch, apiextensions.k8s.io ç­‰)ã€‚ã€åˆ†ç»„ API (Grouped API)ã€‘
      >   ä¸ºä»€ä¹ˆä¼šæœ‰ä¸¤ä¸ªç«¯ç‚¹ï¼š æœ€åˆçš„è®¾è®¡: åœ¨ Kubernetes çš„æ—©æœŸï¼Œæ‰€æœ‰çš„ API èµ„æºå¯¹è±¡ï¼ˆå¦‚ Pod, Service, Node,
      ReplicationController ç­‰ï¼‰éƒ½è¢«æ”¾åœ¨ä¸€ä¸ªæ²¡æœ‰åå­—çš„ API Group é‡Œï¼Œè¿™ä¸ª Group å°±æ˜¯æˆ‘ä»¬æ‰€è¯´çš„â€œæ ¸å¿ƒç»„ (Core Group)
      â€ã€‚ç”±äºå®ƒæ²¡æœ‰åå­—ï¼Œä¸ºäº†è®¿é—®å®ƒï¼ŒAPI Server å°±æä¾›äº† /api/v1 è¿™ä¸ªç‰¹æ®Šçš„ç«¯ç‚¹ã€‚åœ¨å½“æ—¶ï¼Œè¿™å°±æ˜¯ Kubernetes çš„å…¨éƒ¨ APIã€‚
      å‘ç°æ‰©å±•æ€§é—®é¢˜: éšç€é¡¹ç›®çš„å‘å±•ï¼Œå¼€å‘è€…ä»¬å¾ˆå¿«æ„è¯†åˆ°ï¼ŒæŠŠæ‰€æœ‰ä¸œè¥¿éƒ½å¡è¿›ä¸€ä¸ªæ²¡æœ‰åˆ†ç»„çš„ API é‡Œæ˜¯æ— æ³•æ‰©å±•çš„ã€‚å¦‚æœæˆ‘æƒ³æ·»åŠ ä¸€ç»„æ–°çš„
      API ç”¨äºå¤„ç†â€œæ‰¹å¤„ç†ä»»åŠ¡â€ï¼Œæˆ–è€…å¦ä¸€ç»„ API ç”¨äºå¤„ç†â€œç½‘ç»œç­–ç•¥â€ï¼ŒæŠŠå®ƒä»¬éƒ½å †åœ¨æ ¸å¿ƒç»„é‡Œä¼šå˜å¾—éå¸¸æ··ä¹±ã€‚ â€œå‘½åç»„â€çš„è¯ç”Ÿ:
      ä¸ºäº†è§£å†³è¿™ä¸ªé—®é¢˜ï¼ŒKubernetes å¼•å…¥äº†â€œAPI Groupï¼ˆå‘½åç»„ï¼‰â€çš„æ¦‚å¿µã€‚è¿™å…è®¸å¼€å‘è€…æ ¹æ®åŠŸèƒ½é¢†åŸŸå°† API èµ„æºè¿›è¡Œé€»è¾‘åˆ†ç»„ã€‚ä¾‹å¦‚ï¼š
      apps ç»„ï¼šåŒ…å« Deployment, StatefulSet, DaemonSet ç­‰ã€‚batch ç»„ï¼šåŒ…å« Job, CronJob ç­‰ã€‚ networking.k8s.io ç»„ï¼šåŒ…å«
      Ingress, NetworkPolicy ç­‰ã€‚ æ‰€æœ‰è¿™äº›â€œå‘½åç»„â€çš„ API éƒ½é€šè¿‡ä¸€ä¸ªç»Ÿä¸€çš„å‰ç¼€ /apis æ¥è®¿é—®ï¼Œä¾‹å¦‚
      /apis/apps/v1ï¼Œ/apis/batch/v1ã€‚
  
* æ‰§è¡Œè¿™ä¸ªå‘½ä»¤ï¼Œä½ ä¼šçœ‹åˆ° kubectl æ­£åœ¨å‘ apiserver å‘å‡ºä¸€ç³»åˆ—çš„ GET è¯·æ±‚æ¥å‘ç°èµ„æº

  ```shell
  kubectl get pods --v=8
  ```

* æŸ¥è¯¢æ‰€æœ‰å¯ç”¨api

  ```shell
  kubectl api-versions
  ```

* ç›´æ¥è®¿é—® API Serverå»æŸ¥è¯¢æœ‰å“ªäº›æœ‰ç”¨api-versions

  `kubectl` å‘½ä»¤å®é™…ä¸Šæ˜¯åœ¨åå°å‘ Kubernetes API Server å‘é€ HTTP è¯·æ±‚ã€‚æˆ‘ä»¬ä¹Ÿå¯ä»¥æ‰‹åŠ¨æ¨¡æ‹Ÿè¿™ä¸ªè¿‡ç¨‹æ¥æ¢ç´¢ APIã€‚ä¸ºäº†å®‰å…¨åœ°è®¿é—® API Serverï¼Œæœ€ç®€å•çš„æ–¹å¼æ˜¯ä½¿ç”¨ `kubectl proxy`ã€‚

  åœ¨ä¸€ä¸ªç»ˆç«¯ä¸­è¿è¡Œä»¥ä¸‹å‘½ä»¤ï¼Œè®©è¿™ä¸ªç»ˆç«¯ä¿æŒè¿è¡Œã€‚

  ```shell
  kubectl proxy
  ```

  æ‰“å¼€å¦ä¸€ä¸ªç»ˆç«¯ï¼Œä½¿ç”¨ `curl` è¿›è¡ŒæŸ¥è¯¢ã€‚

  ```shell
  curl http://127.0.0.1:8001/api
  ## /apis
  curl http://127.0.0.1:8001/apis
  ```

* æŸ¥è¯¢æ‰€æœ‰å¯ç”¨çš„ API èµ„æº (`api-resources`)

  ```shell
  kubectl api-resources
  # --api-group="" è¡¨ç¤ºæŸ¥è¯¢æ ¸å¿ƒç»„
  kubectl api-resources --api-group=""
  ```

* Without indicating the resource type using the Accept header, the default response for the /api and /apis endpoint is
  an unaggregated discovery document.
  
* the kubectl tool fetches and caches the API specification for enabling command-line completion and other features. The
  two supported mechanisms are as follows:
  
    * Discovery API å°±åƒæ˜¯è¿™æœ¬ä¹¦çš„ â€œç›®å½•â€ã€‚
    * OpenAPI Document å°±åƒæ˜¯è¿™æœ¬ä¹¦ â€œæ­£æ–‡å†…å®¹ä¸­æ‰€æœ‰åè¯çš„è¯¦ç»†è§£é‡Šå’Œè¯­æ³•ç»“æ„è¯´æ˜â€

## k3d æµ‹è¯•ç›¸å…³

* åœ¨ç”Ÿäº§ç¯å¢ƒä¸­ï¼Œé€šå¸¸ä¼šæœ‰å¤šä¸ª Master èŠ‚ç‚¹ï¼ˆåœ¨ k3d/k3s é‡Œè¢«ç§°ä¸º Server èŠ‚ç‚¹ï¼‰æ¥ç¡®ä¿é«˜å¯ç”¨æ€§ã€‚ä½ ä¸ä¼šç›´æ¥è¿æ¥åˆ°æŸä¸€ä¸ª Master èŠ‚ç‚¹ï¼Œå› ä¸ºå¦‚æœé‚£ä¸ªèŠ‚ç‚¹å®•æœºäº†ï¼Œä½ å°±æ— æ³•è®¿é—®é›†ç¾¤äº†ã€‚æ­£ç¡®çš„åšæ³•æ˜¯è¿æ¥åˆ°ä¸€ä¸ª**è´Ÿè½½å‡è¡¡å™¨ (Load Balancer)**ï¼Œç”±å®ƒæ¥å°†ä½ çš„è¯·æ±‚è½¬å‘ç»™åé¢å¥åº·çš„ Master èŠ‚ç‚¹ã€‚

  k3d åœ¨æœ¬åœ°ç”¨ Docker å®¹å™¨å·§å¦™åœ°å¤ç°äº†è¿™å¥—æ¶æ„ï¼š

  1. **`k3d-my-cluster-server-0` å®¹å™¨**: è¿™æ˜¯çœŸæ­£çš„ K3s Serverï¼Œå®ƒåœ¨**å®¹å™¨å†…éƒ¨**è¿è¡Œç€ Kubernetes API Serverï¼Œç›‘å¬ç€ `6443` ç«¯å£ã€‚è¿™ä¸ªå®¹å™¨æ²¡æœ‰ç›´æ¥æš´éœ²ç«¯å£åˆ°å®¿ä¸»æœºï¼Œæ‰€ä»¥ä½ ä»å¤–éƒ¨æ— æ³•ç›´æ¥è®¿é—®å®ƒã€‚
  2. **`k3d-my-cluster-serverlb` å®¹å™¨**: è¿™æ˜¯ä¸€ä¸ªåŸºäº NGINX çš„åå‘ä»£ç†/è´Ÿè½½å‡è¡¡å™¨ã€‚k3d å¯åŠ¨å®ƒï¼Œå¹¶è®©å®ƒç›‘å¬å®¿ä¸»æœºçš„ä¸€ä¸ªç«¯å£ï¼Œç„¶åå°†æµé‡è½¬å‘ç»™åç«¯çš„ K3s Server å®¹å™¨ã€‚

* ä½ çš„ kubectl å¹¶ä¸æ˜¯ç›´æ¥å’Œ K3s Server å®¹å™¨é€šä¿¡ã€‚å®ƒåœ¨å’Œä¸€ä¸ªä½œä¸ºè´Ÿè½½å‡è¡¡å™¨çš„ä»£ç†å®¹å™¨ (k3d-my-cluster-serverlb) é€šä¿¡ã€‚è¿™ä¸ªä»£ç†å®¹å™¨è´Ÿè´£å°†ä½ çš„è¯·æ±‚å®‰å…¨åœ°è½¬å‘ç»™çœŸæ­£çš„ K3s Server å®¹å™¨ã€‚39753 æ˜¯ k3d ä¸ºè¿™ä¸ªè´Ÿè½½å‡è¡¡å™¨éšæœºé€‰æ‹©çš„ã€æš´éœ²åœ¨ä½ å®¿ä¸»æœºä¸Šçš„ç«¯å£ã€‚

* åœ¨k3dé‡Œæµ‹è¯•æ—¶ï¼Œè®¾ç½®type=LoadBalanceræ—¶æ²¡æœ‰ç”¨ï¼Œå³ä½¿è®¾ç½®k3d cluster create my-cluster -p "8080:80@loadbalancer"ï¼Œéœ€è¦æ˜ å°„type=NodePort çš„ç«¯å£ï¼Œå¦‚8080:30080

* åœ¨ç”¨k3dåšæµ‹è¯•æ—¶ï¼Œé›†ç¾¤èŠ‚ç‚¹ "çœ‹" ä¸åˆ°ä½ æœ¬åœ°æœºå™¨ä¸Šçš„ Docker é•œåƒ

  > 1. ä½¿ç”¨ `k3d image import` å‘½ä»¤
  >
  >    `k`3d image import springboot3:v1.0.10 -c my-cluster``
  >
  > 2. **ä¿®æ”¹ä½ çš„ Deployment YAML æ–‡ä»¶**
  >
  >    imagePullPolicy: IfNotPresent # <-- å…³é”®ï¼æ·»åŠ è¿™ä¸€è¡Œ
  >
  > åœ¨ç”Ÿäº§ç¯å¢ƒæˆ–æ›´å¤æ‚çš„å¼€å‘ç¯å¢ƒä¸­ï¼Œæœ€ä½³å®è·µæ˜¯æ­å»ºä¸€ä¸ªé•œåƒä»“åº“ï¼ˆRegistryï¼‰ï¼Œæ¯”å¦‚ Harborã€Nexusï¼Œæˆ–è€…ç›´æ¥ä½¿ç”¨ Docker Hubã€é˜¿é‡Œäº‘ ACR ç­‰ã€‚

## Label


* Labels are key/value pairs. Valid label keys have two segments: an optional prefix and name, separated by a slash (/).

  > Valid label value:
  >
  > - must be 63 characters or less (can be empty),
  > - unless empty, must begin and end with an alphanumeric character (`[a-z0-9A-Z]`),
  > - could contain dashes (`-`), underscores (`_`), dots (`.`), and alphanumerics between.

* The API currently supports two types of selectors: equality-based and set-based. 

* If the prefix is omitted, the label Key is presumed to be private to the user. Automated system components (e.g. kube-scheduler, kube-controller-manager, kube-apiserver, kubectl, or other third-party automation) which add labels to end-user objects must specify a prefix.

* the comma separator acts as a logical AND (&&) operator.

* selector: { component: redis } æ˜¯æ—§ç‰ˆçš„ã€ç®€æ´çš„å†™æ³•ã€‚

  selector: { matchLabels: { component: redis } } æ˜¯æ–°ç‰ˆçš„ã€æ›´ç»“æ„åŒ–ã€æ›´æ¨èçš„å†™æ³•ã€‚

  Kubernetes API åœ¨å¤„ç†ç¬¬ä¸€ç§å†™æ³•æ—¶ï¼Œä¼šè‡ªåŠ¨å°†å…¶ç†è§£ä¸ºç¬¬äºŒç§å†™æ³•ã€‚

* Newer resources, such as Job, Deployment, ReplicaSet, and DaemonSet, support set-based requirements as well.

  > ```yaml
  > selector:
  >   matchLabels:
  >     component: redis
  >   matchExpressions:
  >     - { key: tier, operator: In, values: [cache] }
  >     - { key: environment, operator: NotIn, values: [dev] }
  > 
  > ```

* set-based requirements åº”ç”¨ç”¨å¼•å·åŒ…èµ·æ¥

  > kubectl get pods -l 'environment in (production),tier in (frontend)'

* kubectl get pods -l environment=production,tier=frontend

* kubectl get pods -Lapp -Ltier -Lrole

  > â€˜-Lâ€™ å‚æ•°ä¸æ˜¯è¿‡æ»¤ä½œç”¨ï¼Œè€Œæ˜¯åœ¨æœ€ç»ˆçš„æŸ¥è¯¢ç»“æœä¸­ä»¥åˆ—çš„å½¢å¼æ˜¾ç¤º

* æ›´æ–°label

  > ```shell
  > kubectl label pods -l app=nginx tier=fe
  > ```
  >
  > This first filters all pods with the label "app=nginx", and then labels them with the "tier=fe"ã€‚é™¤äº†ç”¨-l app=nginxæ ‡ç­¾æ¥è¿‡æ»¤ï¼Œè¿˜å¯ä»¥ç”¨podçš„åå­—æ¥è¿‡æ»¤éœ€è¦æ“ä½œçš„pods
  >
  > é»˜è®¤æƒ…å†µä¸‹ï¼Œå½“å·²ç»å­˜åœ¨tieræ ‡ç­¾æ—¶ï¼Œä¸ä¼šæ›´æ–°æˆåŠŸã€‚å¯ä»¥åŠ å…¥`kubectl label --overwrite pods`è¿™ä¸ªå‚æ•°

## Namespace


* Namespace-based scoping is applicable only for namespaced objects (e.g. Deployments, Services, etc.) and not for cluster-wide objects (e.g. StorageClass, Nodes, PersistentVolumes, etc.)

* For a production cluster, consider not using the default namespace. Instead, make other namespaces and use those.

* Kubernetes starts with four initial namespaces:

  > 1. default
  > 2. kube-node-lease
  > 3. kube-public
  > 4. kube-system

* Avoid creating namespaces with the prefix kube-, since it is reserved for Kubernetes system namespaces.

* kubectl get namespace

* To set the namespace for a current request, use the --namespace flag.

  > ```shell
  > kubectl run nginx --image=nginx --namespace=[insert-namespace-name-here]
  > kubectl get pods --namespace=[insert-namespace-name-here]
  > ```

* You can permanently save the namespace for all subsequent kubectl commands in that context.

  > ```shell
  > kubectl config set-context --current --namespace=[insert-namespace-name-here]
  > # Validate it
  > kubectl config view --minify | grep namespace:
  > ```

* Not all objects are in a namespace

  > However namespace resources are not themselves in a namespace. And low-level resources, such as nodes and persistentVolumes, are not in any namespace.
  >
  > ```shell
  > # In a namespace
  > kubectl api-resources --namespaced=true
  > 
  > # Not in a namespace
  > kubectl api-resources --namespaced=false
  > ```

* The Kubernetes control plane sets an immutable label kubernetes.io/metadata.name on all namespaces. The value of the label is the namespace name

  > kubectl describe namespaces kube-system

* The keys and the values in the map must be strings. In other words, you cannot use numeric, boolean, list or other types for either the keys or the values.

## Annotations


* Annotations are key/value pairs. Valid annotation keys have two segments: an optional prefix and name, separated by a slash (/). 

  > The name segment is required and must be 63 characters or less, beginning and ending with an alphanumeric character (`[a-z0-9A-Z]`) with dashes (`-`), underscores (`_`), dots (`.`), and alphanumerics between.

* Shared labels and annotations share a common prefix: app.kubernetes.io. Labels without a prefix are private to users. The shared prefix ensures that shared labels do not interfere with custom user labels.

  > **Shared Labels** æ˜¯ä¸€å¥— **å®˜æ–¹æ¨èçš„ã€æ ‡å‡†åŒ–çš„æ ‡ç­¾**ã€‚å®ƒä»¬ä½¿ç”¨ `app.kubernetes.io/` è¿™ä¸ªç»Ÿä¸€çš„å‰ç¼€ï¼Œç›®çš„æ˜¯ä¸ºäº†è®©ä¸åŒçš„å·¥å…·ã€å›¢é˜Ÿå’Œç”¨æˆ·èƒ½å¤Ÿç”¨ä¸€ç§é€šç”¨çš„æ–¹å¼æ¥æè¿°å’Œè¯†åˆ«åœ¨ Kubernetes ä¸­è¿è¡Œçš„åº”ç”¨ç¨‹åº

* The metadata is organized around the concept of an application. Kubernetes is not a platform as a service (PaaS) and doesn't have or enforce a formal notion of an application. Instead, applications are informal and described with metadata. The definition of what an application contains is loose.

## Field selectors


* Field selectors are essentially resource filters. By default, no selectors/filters are applied, meaning that all resources of the specified type are selected. This makes the kubectl queries kubectl get pods and kubectl get pods --field-selector "" equivalent.

* You can use the =, ==, and != operators with field selectors (= and == mean the same thing). 

  > kubectl get services --all-namespaces --field-selector metadata.namespace!=default

* As with label and other selectors, field selectors can be chained together as a comma-separated list. 

  > kubectl get pods --field-selector=status.phase!=Running,spec.restartPolicy=Always

## Finalizer


* Finalizer æ˜¯ä¸€ä¸ªå­˜åœ¨äºèµ„æºå¯¹è±¡ metadata ä¸­çš„å­—ç¬¦ä¸²åˆ—è¡¨ã€‚

* è¿™ä¸ª Finalizer ç¡®ä¿äº†å½“ä½ åˆ é™¤è¿™ä¸ª Service æ—¶ï¼ŒKubernetes ä¼šå…ˆè°ƒç”¨äº‘å¹³å°çš„ API å»åˆ é™¤é‚£ä¸ªçœŸå®çš„ã€ä¼šäº§ç”Ÿè´¹ç”¨çš„è´Ÿè½½å‡è¡¡å™¨ï¼Œç„¶åå†åˆ é™¤ Service å¯¹è±¡æœ¬èº«ã€‚å¦‚æœæ²¡æœ‰è¿™ä¸ªæœºåˆ¶ï¼Œä½ å¯èƒ½ä¼šç•™ä¸‹å¾ˆå¤šæ— äººç®¡ç†çš„â€œåƒµå°¸â€äº‘èµ„æºã€‚

  > **Finalizer**: `service.kubernetes.io/load-balancer-cleanup` (åœ¨ä¸€äº›äº‘å‚å•†çš„å®ç°ä¸­)

* ä¸ºä»€ä¹ˆèµ„æºä¼šå¡åœ¨ Terminating çŠ¶æ€ï¼ŸğŸš¨
  è¿™æ˜¯ä½ åœ¨å®è·µä¸­ä¸€å®šä¼šé‡åˆ°çš„ç»å…¸é—®é¢˜ã€‚å½“ä¸€ä¸ªèµ„æºé•¿æ—¶é—´å¤„äº Terminating çŠ¶æ€æ—¶ï¼Œå‡ ä¹ 100% æ˜¯ Finalizer å¯¼è‡´çš„ã€‚

  > **åŸå› **ï¼šè´Ÿè´£æ¸…ç†å¹¶ç§»é™¤é‚£ä¸ª Finalizer çš„æ§åˆ¶å™¨**æ— æ³•å®Œæˆå®ƒçš„å·¥ä½œ**ã€‚

* Finalizers are namespaced keys that tell Kubernetes to wait until specific conditions are met before it fully deletes resources marked for deletion. Finalizers alert controllers to clean up resources the deleted object owned.

  > **Marked for deletion (æ ‡è®°ä¸ºåˆ é™¤)**: èµ„æºæœ‰äº† `deletionTimestamp`ï¼Œå¤„äº `Terminating` çŠ¶æ€ã€‚å®ƒå¯¹å¤–å·²ç»â€œæ­»äº¡â€ï¼ˆæ¯”å¦‚ Pod ä¸å†æ¥æ”¶æµé‡ï¼‰ï¼Œä½†å®ƒçš„â€œå°¸ä½“â€ï¼ˆåœ¨ etcd ä¸­çš„è®°å½•ï¼‰è¿˜åœ¨ã€‚
  >
  > **Fully deleted (å½»åº•åˆ é™¤)**: èµ„æºçš„è®°å½•ä» etcd ä¸­è¢«å½»åº•æŠ¹é™¤ï¼Œå®ƒä¸å¤å­˜åœ¨äº†ã€‚
  >
  > **Specific conditions are met (ç‰¹å®šæ¡ä»¶è¢«æ»¡è¶³)**: è¿™ä¸ªâ€œç‰¹å®šæ¡ä»¶â€éå¸¸æ˜ç¡®ï¼Œ**æŒ‡çš„å°±æ˜¯** `metadata.finalizers` **åˆ—è¡¨å˜ä¸ºç©º**ã€‚
  >
  > é‚£ä¹ˆè°æ¥æ¸…ç©ºè¿™ä¸ªåˆ—è¡¨å‘¢ï¼Ÿç­”æ¡ˆæ˜¯**æ§åˆ¶å™¨ (Controller)**ã€‚
  >
  > - æ¯ä¸ª Finalizer å­—ç¬¦ä¸²éƒ½å¯¹åº”ä¸€ä¸ªæ­£åœ¨è¿è¡Œçš„æ§åˆ¶å™¨ã€‚
  > - è¿™ä¸ªæ§åˆ¶å™¨ä¸€ç›´åœ¨ç›‘æ§ï¼Œå½“å®ƒå‘ç°è‡ªå·±è´Ÿè´£çš„èµ„æºå‡ºç°äº† `deletionTimestamp` æ—¶ï¼Œå®ƒå°±çŸ¥é“è¯¥å¹²æ´»äº†ï¼ˆæ‰§è¡Œæ¸…ç†ä»»åŠ¡ï¼‰ã€‚
  > - æ¸…ç†ä»»åŠ¡å®Œæˆåï¼ˆæ¯”å¦‚äº‘ç¡¬ç›˜è¢«åˆ äº†ï¼Œæ•°æ®åº“å¤‡ä»½å¥½äº†ï¼‰ï¼Œæ§åˆ¶å™¨å°±ä¼šå‘èµ·ä¸€ä¸ª API è¯·æ±‚ï¼ŒæŠŠè‡ªå·±è´Ÿè´£çš„é‚£ä¸ª Finalizer å­—ç¬¦ä¸²ä»åˆ—è¡¨ä¸­**ç§»é™¤**ã€‚
  > - å½“æ‰€æœ‰æ§åˆ¶å™¨éƒ½å®Œæˆäº†è‡ªå·±çš„ä»»åŠ¡ï¼Œ`finalizers` åˆ—è¡¨å°±å˜ç©ºäº†ã€‚
  >
  > å®ƒå®é™…ä¸Šæ˜¯ä¸€ä¸ª**å­—ç¬¦ä¸²**ã€‚è¿™äº›å­—ç¬¦ä¸²å­˜åœ¨äºä¸€ä¸ªåˆ—è¡¨é‡Œï¼Œä½ç½®åœ¨ `metadata.finalizers`
  >
  > å®ƒä»¬åƒå¸¦æœ‰åç©ºé—´çš„é”®ä¸€æ ·ï¼Œæ˜¯ç‹¬ä¸€æ— äºŒçš„æ ‡è¯†ç¬¦
  >
  > ç®€å•æ¥è¯´ï¼šä½ å¯ä»¥æŠŠå®ƒç†è§£ä¸ºâ€œå¸¦æœ‰å”¯ä¸€å‰ç¼€çš„ç‰¹æ®Šæ ‡ç­¾â€ã€‚
  >
  > ```yaml
  > metadata:
  >   finalizers:
  >   - kubernetes.io/pv-protection  # ä¸€ä¸ªéµå¾ª "namespaced key" æ ¼å¼çš„å­—ç¬¦ä¸²
  >   - another.tool.com/do-backup    # å¦ä¸€ä¸ªéµå¾ªåŒæ ·æ ¼å¼çš„å­—ç¬¦ä¸²
  > ```

* Custom finalizer names must be publicly qualified finalizer names, such as example.com/finalizer-name. Kubernetes enforces this format; the API server rejects writes to objects where the change does not use qualified finalizer names for any custom finalizer.

* Dependent objects also have an ownerReferences.blockOwnerDeletion field that takes a boolean value and controls whether specific dependents can block garbage collection from deleting their owner object. Kubernetes automatically sets this field to true if a controller (for example, the Deployment controller) sets the value of the metadata.ownerReferences field. You can also set the value of the blockOwnerDeletion field manually to control which dependents block garbage collection.

  > å…³ç³»é“¾: Deployment -> ReplicaSet -> Podã€‚
  >
  > åˆ é™¤é“¾: åˆ é™¤ Deployment -> åˆ é™¤ ReplicaSet -> åˆ é™¤ Podã€‚
  >
  > blockOwnerDeletion: true: æ˜¯ä¸€ä¸ª â€œåˆ¹è½¦â€ã€‚Dependent å¯¹è±¡å¯¹ Owner è¯´ï¼šâ€œåˆ«åˆ æˆ‘è€æ¿ï¼Œé™¤éæˆ‘å…ˆèµ°ï¼â€
  >
  > kubectl delete deployment è§¦å‘çš„æ˜¯ä¸€ä¸ªâ€œæœ‰åºè§£æ•£â€ï¼Œè€Œéâ€œæ–©é¦–è¡ŒåŠ¨ã€ç›´æ¥åˆ é™¤deploymentã€‘â€

* In foreground deletion, it adds the foreground finalizer so that the controller must delete dependent resources that also have ownerReferences.blockOwnerDeletion=true before it deletes the owner.

* kubectl delete deployment my-app --cascade=orphan

  > **ä¼šå‘ç”Ÿä»€ä¹ˆï¼Ÿ**
  >
  > 1. `Deployment` **å¯¹è±¡è¢«ç«‹å³åˆ é™¤**ï¼š`my-app` è¿™ä¸ª `Deployment` èµ„æºç¬é—´å°±æ¶ˆå¤±äº†ã€‚
  > 2. `ReplicaSet` **å’Œ** `Pod` **å®Œå¥½æ— æŸ**ï¼šä½ ä¼šæƒŠè®¶åœ°å‘ç°ï¼Œ`ReplicaSet` å’Œæ‰€æœ‰çš„ `Pod` ä¾ç„¶åœ¨è¿è¡Œï¼
  > 3. `ReplicaSet` **æˆä¸ºå­¤å„¿**ï¼šå¦‚æœä½ æŸ¥çœ‹é‚£ä¸ªå¹¸å­˜çš„ `ReplicaSet` çš„ YAML (`kubectl get rs [rs-name] -o yaml`)ï¼Œä½ ä¼šå‘ç°å®ƒ `metadata` é‡Œçš„ `ownerReferences` å­—æ®µ**å·²ç»ä¸è§äº†**ã€‚å®ƒä¸å†å±äºä»»ä½•äººï¼Œå˜æˆäº†ä¸€ä¸ªç‹¬ç«‹çš„ã€æ²¡äººç®¡ç†çš„ `ReplicaSet`ã€‚

## å…¶å®ƒ

* `kind: Ingress` ä¼šæš´éœ²ä¸€ä¸ª IP åœ°å€å—ï¼Ÿ

  > ä¸ä¼šï¼Œ`Ingress` èµ„æºæœ¬èº«ä¸ä¼šã€‚ä¸€ä¸ª `kind: Ingress` çš„ YAML æ–‡ä»¶ï¼Œå®ƒä»…ä»…æ˜¯**ä¸€å¥—è§„åˆ™**çš„é›†åˆï¼Œå°±åƒä¸€å¼ å†™ç€â€œ`a.com` çš„æµé‡è¯·èµ°Aé—¨ï¼Œ`b.com` çš„æµé‡è¯·èµ°Bé—¨â€çš„è¯´æ˜ä¹¦ã€‚è¿™å¼ è¯´æ˜ä¹¦æœ¬èº«å¹¶æ²¡æœ‰åœ°å€ï¼Œå®ƒéœ€è¦è¢«äººï¼ˆä¹Ÿå°±æ˜¯ `Ingress Controller`ï¼‰å»é˜…è¯»å’Œæ‰§è¡Œã€‚
  >
  > çœŸæ­£æš´éœ² IP åœ°å€çš„ï¼Œæ˜¯ `Ingress Controller` çš„ `Service`ï¼
  >
  > å›é¡¾ä¸€ä¸‹ `Ingress Controller` æ˜¯å¦‚ä½•è¢«å®‰è£…çš„ï¼š
  >
  > 1. **Ingress Controller æ˜¯ä¸€ä¸ªéœ€è¦è¢«**`å®‰è£…`**åˆ°é›†ç¾¤ä¸­çš„åº”ç”¨**ï¼Œå®ƒä¸æ˜¯ K8s è‡ªå¸¦çš„ã€‚
  > 2. **å®‰è£…çš„æœ¬è´¨**æ˜¯åº”ç”¨ä¸€å¥—åŒ…å«äº† `Deployment`ã€`Service`ã€`RBAC` ç­‰èµ„æºçš„ YAML æ–‡ä»¶ã€‚
  > 3. **K3s ç”¨æˆ·æœ€å¹¸ç¦**ï¼Œå› ä¸º K3s å·²ç»å†…ç½®äº† **Traefik**ï¼Œæ— éœ€æ‰‹åŠ¨å®‰è£…ã€‚ä½ åªéœ€è¦ç›´æ¥åœ¨ `Ingress` ä¸­ä½¿ç”¨ `ingressClassName: "traefik"` å³å¯ã€‚
  > 4. åœ¨**æ ‡å‡† K8s ç¯å¢ƒ**ä¸­ï¼Œæœ€å¸¸ç”¨çš„é€‰æ‹©æ˜¯ **NGINX Ingress Controller**ï¼Œå¯ä»¥é€šè¿‡å®˜æ–¹ `kubectl apply` å‘½ä»¤æˆ– `Helm` Chart æ¥å®‰è£…ã€‚
  > 5. **`IngressClass` èµ„æºæ˜¯åœ¨å®‰è£… Controller çš„è¿‡ç¨‹ä¸­è¢«è‡ªåŠ¨åˆ›å»ºçš„**ã€‚å®ƒåƒä¸€ä¸ªâ€œå‘Šç¤ºç‰Œâ€ï¼Œå‘Šè¯‰æ•´ä¸ªé›†ç¾¤ï¼šâ€œå˜¿ï¼Œæˆ‘è¿™é‡Œæœ‰ä¸€ä¸ªåä¸º `nginx` (æˆ– `traefik`) çš„ Controllerï¼Œä½ ä»¬è°éœ€è¦å¤„ç† Ingress è§„åˆ™ï¼Œå°±é€šè¿‡ `ingressClassName` æ¥æ‰¾æˆ‘ï¼â€
  >
  > ç°åœ¨ï¼Œ`Ingress` (è§„åˆ™)ã€`Ingress Controller` (æ‰§è¡Œè€…) å’Œ `IngressClass` (è”ç³»æ–¹å¼) è¿™ä¸‰è€…ä¹‹
  >
  > å®ƒé€šå¸¸åŒ…å«ä¸€ä¸ª `Deployment` (è¿è¡Œ Controller çš„ Pods) å’Œä¸€ä¸ª `Service` (æŠŠè¿™äº› Pods æš´éœ²å‡ºå»)ã€‚è¿™ä¸ª `Service` çš„ç±»å‹é€šå¸¸æ˜¯ `LoadBalancer` æˆ– `NodePort`ã€‚
  >
  > - å½“ `Service` çš„ç±»å‹æ˜¯ `LoadBalancer` æ—¶ï¼Œäº‘æœåŠ¡å•†ä¼šä¸º**è¿™ä¸ª Service**åˆ†é…ä¸€ä¸ª**å…¬ç½‘ IP åœ°å€**ã€‚
  > - å½“ `Service` çš„ç±»å‹æ˜¯ `NodePort` æ—¶ï¼Œä½ å¯ä»¥é€šè¿‡**ä»»ä½•ä¸€ä¸ªèŠ‚ç‚¹çš„ IP** + `NodePort` ç«¯å£æ¥è®¿é—®ã€‚
  >
  > é‚£ä¸ªå®è´µçš„ã€å”¯ä¸€çš„ã€å¯¹å¤–æœåŠ¡çš„å…¬ç½‘ IP åœ°å€ï¼Œæ˜¯å±äº **Ingress Controller çš„ Service** çš„ï¼Œè€Œä¸æ˜¯å±äºä½ åˆ›å»ºçš„æŸä¸€ä¸ª `Ingress` è§„åˆ™å¯¹è±¡çš„ã€‚
  >
  > ä½ å¯ä»¥é€šè¿‡ä»¥ä¸‹å‘½ä»¤æŸ¥çœ‹åˆ°è¿™ä¸ª IP åœ°å€ï¼š
  >
  > ```shell
  > # æŸ¥çœ‹ Ingress Controller çš„ Service
  > # æ³¨æ„å‘½åç©ºé—´ï¼Œå¦‚æœä½ æ˜¯ç”¨ helm è£…çš„ nginx-ingressï¼Œé‚£å°±åœ¨ ingress-nginx å‘½åç©ºé—´
  > # å¦‚æœæ˜¯ k3s è‡ªå¸¦çš„ traefikï¼Œé‚£å°±åœ¨ kube-system
  > kubectl get service -n ingress-nginx 
  > 
  > # ä½ ä¼šçœ‹åˆ°ç±»ä¼¼è¿™æ ·çš„è¾“å‡º
  > # NAME                       TYPE           CLUSTER-IP      EXTERNAL-IP      PORT(S)                      AGE
  > # ingress-nginx-controller   LoadBalancer   10.43.151.108   203.0.113.55     80:32168/TCP,443:30256/TCP   10m
  > #                                                          ^^^^^^^^^^^^
  > # å°±æ˜¯è¿™ä¸ª IPï¼
  > ```


* æ•…éšœæ’æŸ¥ä¸‰æ­¥æ³•

  > ç¬¬ 1 æ­¥ï¼šç¡®è®¤ Pods æ˜¯å¦å¥åº·è¿è¡Œ
  >
  > ```shell
  > kubectl get pods -o wide
  > ```
  >
  > ç¬¬ 2 æ­¥ï¼šç¡®è®¤ Service æ˜¯å¦æ­£ç¡®å…³è”äº† Pods
  >
  > ```shell
  > kubectl describe service nginx-service
  > ```
  >
  > **æ­£ç¡®çš„çŠ¶æ€**: `Endpoints` åé¢åº”è¯¥åˆ—å‡ºäº†ä¸€ä¸ªæˆ–å¤šä¸ª IP åœ°å€å’Œç«¯å£ï¼Œè¿™äº› IP åº”è¯¥ä¸ä½ åœ¨ä¸Šä¸€æ­¥ä¸­çœ‹åˆ°çš„ Pod IP å®Œå…¨ä¸€è‡´ã€‚`Endpoints:         10.42.0.5:80,10.42.0.6:80`
  >
  > ç¬¬ 3 æ­¥ï¼šç¡®è®¤ k3d èŠ‚ç‚¹çš„ç«¯å£æ˜ å°„ (æœ€å¯èƒ½çš„åŸå› )

* æœ€å¿«ã€æœ€ç›´æ¥çš„ç»•è¿‡ç½‘ç»œé—®é¢˜çš„æ–¹æ³•ï¼Œæˆ‘ä»¬åœ¨ä¸Šæ¬¡è®¨è®ºä¸­ä¹Ÿæåˆ°äº†ã€‚å®ƒä¸ä¾èµ–ä»»ä½•ç«¯å£æ˜ å°„ï¼Œè€Œæ˜¯ç›´æ¥åœ¨ä½ çš„ç”µè„‘å’Œ Service ä¹‹é—´å»ºç«‹ä¸€æ¡éš§é“ã€‚

  > ```shell
  > # åœ¨æ–°ç»ˆç«¯ä¸­è¿è¡Œ
  > kubectl port-forward service/nginx-service 8080:80
  > ```

* MetalLB (å¼ºçƒˆæ¨è) è¿™æ˜¯åœ¨è‡ªå»ºé›†ç¾¤ï¼ˆBare-Metalï¼‰ä¸­å®ç° type: LoadBalancer çš„æœ€ä½³å®è·µæ–¹æ¡ˆã€‚MetalLB æ˜¯ä¸€ä¸ªå¼€æºé¡¹ç›®ï¼Œå®ƒèƒ½ä¸ºä½ çš„é›†ç¾¤æ¨¡æ‹Ÿäº‘æœåŠ¡å•†çš„è´Ÿè½½å‡è¡¡å™¨åŠŸèƒ½ã€‚

* ä½¿ç”¨ kubectl explain å‘½ä»¤ï¼šè¿™æ˜¯ä¸€ä¸ªéå¸¸æœ‰ç”¨çš„å‘½ä»¤ï¼Œå¯ä»¥å¸®åŠ©ä½ äº†è§£ä»»ä½• Kubernetes èµ„æºçš„ç»“æ„å’Œå­—æ®µã€‚ä¾‹å¦‚ï¼Œå¦‚æœä½ æƒ³çŸ¥é“ Deployment çš„ apiVersion

* ä¸€ä¸ªå®Œæ•´çš„åº”ç”¨[ç³»ç»Ÿ]ï¼Œä¸€èˆ¬åªæœ‰ä¸€ä¸ªtypeä¸ºloadbalancerçš„service?

  > * å¯¹äºä¸€ä¸ªå®Œæ•´çš„ã€ç°ä»£åŒ–çš„åº”ç”¨ç³»ç»Ÿï¼ˆç‰¹åˆ«æ˜¯åŸºäºå¾®æœåŠ¡æ¶æ„çš„ Web åº”ç”¨ï¼‰ï¼Œé€šå¸¸æœ€ä½³å®è·µå°±æ˜¯åªä½¿ç”¨ä¸€ä¸ª Type=LoadBalancer çš„ Serviceã€‚æ ‡å‡†çš„åº”ç”¨æš´éœ²æ¶æ„ï¼šâ€œLoadBalancer + Ingress Controllerâ€
  >
  > * å¦‚æœä½ çš„åº”ç”¨ç³»ç»ŸåŒ…å«ä¸€äº›é HTTP/HTTPS çš„æœåŠ¡ï¼Œæ¯”å¦‚ï¼š
  >
  >   * ä¸€ä¸ªéœ€è¦ç›´æ¥æš´éœ²ç»™å¤–éƒ¨å®¢æˆ·ç«¯çš„ æ•°æ®åº“ (å¦‚ PostgreSQL)ã€‚
  >   * ä¸€ä¸ª MQTT æ¶ˆæ¯ä»£ç†æœåŠ¡ã€‚
  >   * ä¸€ä¸ª SFTP æ–‡ä»¶æœåŠ¡ã€‚
  >
  >   è¿™äº›æœåŠ¡å·¥ä½œåœ¨ TCP/UDP å±‚ï¼ŒIngress Controllerï¼ˆé€šå¸¸ä¸º HTTP è®¾è®¡ï¼‰æ— æ³•å¤„ç†ã€‚åœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œä¸ºè¿™äº›ç‰¹å®šçš„æœåŠ¡å†é¢å¤–åˆ›å»ºä¸€ä¸ªç‹¬ç«‹çš„ Type=LoadBalancer Service æ˜¯å®Œå…¨åˆç†çš„ã€‚

* In case of a Node, it is implicitly assumed that an instance using the same name will have the same state (e.g.network settings, root disk contents) and attributes like node labels.

  > è¿™é‡Œçš„instanceæ˜¯æŒ‡è™šæ‹Ÿæœºæˆ–è€…ç‰©ç†æœºã€‚ Kubernetes
  > è®¤â€˜åâ€™ä¸è®¤â€˜äººâ€™ã€‚å®ƒæŠŠèŠ‚ç‚¹åç§°å½“ä½œèº«ä»½è¯å·ã€‚å¦‚æœä¸€ä¸ªæ–°äººæ‹¿äº†æ—§äººçš„èº«ä»½è¯å·æ¥æŠ¥åˆ°ï¼Œç³»ç»Ÿä¼šæŠŠä»–å½“æˆæ—§äººï¼Œä½†è¿™ä¸ªæ–°äººçš„èƒ½åŠ›å’ŒèƒŒæ™¯ï¼ˆç£ç›˜å†…å®¹ã€ç¡¬ä»¶å±æ€§ï¼‰æ˜¯å…¨æ–°çš„ã€‚è¿™ç§èº«ä»½ä¸å®é™…èƒ½åŠ›çš„ä¸åŒ¹é…ï¼Œæ­£æ˜¯å¾ˆå¤šè¯¡å¼‚é—®é¢˜çš„æ ¹æºã€‚è¯·åŠ¡å¿…ç¡®ä¿åœ¨æ›¿æ¢èŠ‚ç‚¹æ—¶ï¼Œå…ˆâ€˜æ³¨é”€â€™æ—§çš„èº«ä»½ä¿¡æ¯ï¼ˆkubectl
  > delete nodeï¼‰ï¼Œå†è®©æ–°äººç”¨è‡ªå·±çš„èº«ä»½æ³¨å†Œã€‚

* Register the node with the given list of taints

  > å¯ä»¥æŠŠ Taint (æ±¡ç‚¹) æƒ³è±¡æˆèŠ‚ç‚¹ï¼ˆNodeï¼‰ä¸Šçš„ä¸€ä¸ªâ€œæ’æ–¥æ ‡ç­¾â€æˆ–è€…â€œè°¢ç»å…¥å†…â€çš„ç‰Œå­ã€‚ ä¸€æ—¦ä¸€ä¸ªèŠ‚ç‚¹è¢«æ‰“ä¸Šäº†æŸä¸ª
  > Taintï¼ŒKubernetes çš„è°ƒåº¦å™¨ï¼ˆSchedulerï¼‰é»˜è®¤å°±ä¸ä¼šæŠŠä»»ä½• Pod è°ƒåº¦åˆ°è¿™ä¸ªèŠ‚ç‚¹ä¸Šã€‚è¿™å°±å¥½åƒä¸€ä¸ªæˆ¿é—´é—¨å£æŒ‚ç€â€œè¯·å‹¿æ‰“æ‰°â€çš„ç‰Œå­ï¼Œæ­£å¸¸æƒ…å†µä¸‹ï¼Œæ²¡æœ‰äººä¼šè¿›å»ã€‚

## Container

### Container hooks

- PostStart

  However, if the `PostStart` hook takes too long to execute or if it hangs, it can prevent the container from transitioning to a `running` state.

- PreStop

  `PreStop` hooks are not executed asynchronously from the signal to stop the Container; the hook must complete its execution before the TERM signal can be sent. 

> **Hook å¤±è´¥çš„å½±å“**ï¼š
>
> - `postStart` Hook å¤±è´¥ï¼šå¦‚æœ `postStart` Hook æ‰§è¡Œå¤±è´¥ï¼Œå®¹å™¨å°†æ— æ³•è¿›å…¥ `Running` çŠ¶æ€ï¼Œ`kubelet` ä¼šæ€æ­»å¹¶å°è¯•é‡å¯è¿™ä¸ªå®¹å™¨ï¼Œå¯¼è‡´ Pod è¿›å…¥ `CrashLoopBackOff` çŠ¶æ€ã€‚
> - `preStop` Hook å¤±è´¥ï¼š`preStop` Hook çš„å¤±è´¥ä¸ä¼šé˜»æ­¢å®¹å™¨çš„ç»ˆæ­¢ã€‚Kubernetes åœ¨å°è¯•æ‰§è¡Œ `preStop` Hook åï¼ˆæ— è®ºæˆåŠŸä¸å¦ï¼‰ï¼Œä»ç„¶ä¼šå‘å®¹å™¨çš„ä¸»è¿›ç¨‹å‘é€ `TERM` ä¿¡å·ã€‚
>
> å…¶å®ä¹Ÿå¯ä»¥æ€»ç»“ä¸ºè¿™ä¸¤ä¸ªhookåªè¦æœ‰ä¸€ä¸ªå¤±è´¥ï¼Œå®¹å™¨éƒ½ä¼šè¢«killed

### Hook handler implementations

- Exec

1. **æ‰§è¡Œç¯å¢ƒ**ï¼š`Exec` ç±»å‹çš„ Hook Handler **å®Œå…¨åœ¨å®¹å™¨å†…éƒ¨æ‰§è¡Œ**ã€‚å®ƒå’Œä½ åœ¨å®¹å™¨å¯åŠ¨åä½¿ç”¨ `kubectl exec` æˆ– `docker exec` è¿›å…¥å®¹å™¨æ‰§è¡Œå‘½ä»¤çš„ç¯å¢ƒæ˜¯ä¸€æ¨¡ä¸€æ ·çš„ã€‚
2. **èµ„æºå½’å±**ï¼šå› æ­¤ï¼Œè¿™ä¸ªè„šæœ¬æˆ–å‘½ä»¤æ‰€æ¶ˆè€—çš„ **æ‰€æœ‰èµ„æºï¼ˆCPUã€å†…å­˜ç­‰ï¼‰éƒ½è®¡ç®—åœ¨è¯¥å®¹å™¨çš„è´¦ä¸Š**ã€‚å®ƒä¼šå—åˆ°ä¸ºè¯¥å®¹å™¨é…ç½®çš„ `resources.limits` å’Œ `resources.requests` çš„çº¦æŸã€‚
3. - 

- HTTP
- Sleep

>  `httpGet`, `tcpSocket` ([deprecated](https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.31/#lifecyclehandler-v1-core)) and `sleep` are executed by the kubelet process, and `exec` is executed in the container.

### Hook delivery guarantees

è¿™äº›hookå¯èƒ½ä¼šè¿è¡Œå¤šæ¬¡ã€‚è¿™ä¸ªæ¦‚å¿µåœ¨åˆ†å¸ƒå¼ç³»ç»Ÿä¸­éå¸¸å¸¸è§ï¼Œè¢«ç§°ä¸º **â€œè‡³å°‘ä¸€æ¬¡ (At-Least-Once)â€** æŠ•é€’è¯­ä¹‰

### Debugging Hook handlers

è¿™äº›Hook handlerså¦‚æœæ‰§è¡Œå¤±è´¥ï¼Œå¯ä»¥æ‰§è¡Œåƒç±»ä¼¼çš„è¯­å¥æ¥æŸ¥çœ‹æ—¥å¿—`kubectl describe pod lifecycle-demo`

## Workloads

A workload is an application running on Kubernetes. Whether your workload is a single component or several that work together, on Kubernetes you run it inside a set of [*pods*](https://kubernetes.io/docs/concepts/workloads/pods/). In Kubernetes, a Pod represents a set of running [containers](https://kubernetes.io/docs/concepts/containers/) on your cluster.

several **built-in workload resources**:

* [Deployment](https://kubernetes.io/docs/concepts/workloads/controllers/deployment/) and [ReplicaSet](https://kubernetes.io/docs/concepts/workloads/controllers/replicaset/) (replacing the legacy resource [ReplicationController](https://kubernetes.io/docs/reference/glossary/?all=true#term-replication-controller)).
* [StatefulSet](https://kubernetes.io/docs/concepts/workloads/controllers/statefulset/) 
* [DaemonSet](https://kubernetes.io/docs/concepts/workloads/controllers/daemonset/) defines Pods that provide facilities that are local to nodes. 
* [Job](https://kubernetes.io/docs/concepts/workloads/controllers/job/) and [CronJob](https://kubernetes.io/docs/concepts/workloads/controllers/cron-jobs/) provide different ways to define tasks that run to completion and then stop. You can use a [Job](https://kubernetes.io/docs/concepts/workloads/controllers/job/) to define a task that runs to completion, just once. You can use a [CronJob](https://kubernetes.io/docs/concepts/workloads/controllers/cron-jobs/) to run the same Job multiple times according a schedule.

In the wider Kubernetes ecosystem, you can find third-party workload resources that provide additional behaviors. Using a [custom resource definition](https://kubernetes.io/docs/concepts/extend-kubernetes/api-extension/custom-resources/), you can add in a third-party workload resource if you want a specific behavior that's not part of Kubernetes' core. 

### Pods

*Pods* are the smallest deployable units of computing that you can create and manage in Kubernetes. ä½ å¯ä»¥æŠŠä¸€ä¸ª Pod æƒ³è±¡æˆä¸€å°ç‹¬ç«‹çš„â€œé€»è¾‘ä¸»æœºâ€æˆ–è™šæ‹Ÿæœºã€‚è¿™å°â€œä¸»æœºâ€æœ‰è‡ªå·±å”¯ä¸€çš„ IP åœ°å€ã€‚

Pods in a Kubernetes cluster are used in two main ways:

- **Pods that run a single container**. 

- **Pods that run multiple containers that need to work together**. 

  You should use this pattern only in specific instances in which your containers are tightly coupled. You don't need to run multiple containers to provide replication (for resilience or capacity);

#### Using Pods

```yaml
apiVersion: v1
kind: Pod
metadata:
  name: nginx
spec:
  containers:
  - name: nginx
    image: nginx:1.14.2
    ports:
    - containerPort: 80
```

Pods are generally not created directly and are created using workload resources. Instead, create them using workload resources such as [Deployment](https://kubernetes.io/docs/concepts/workloads/controllers/deployment/) or [Job](https://kubernetes.io/docs/concepts/workloads/controllers/job/). If your Pods need to track state, consider the [StatefulSet](https://kubernetes.io/docs/concepts/workloads/controllers/statefulset/) resource.

#### Working with Pods

Pods are designed as relatively ephemeral, disposable entities. The Pod remains on that node until the Pod finishes execution, the Pod object is deleted, the Pod is *evicted* for lack of resources, or the node fails.

> #### Note:
>
> Restarting a container in a Pod should not be confused with restarting a Pod. A Pod is not a process, but an environment for running container(s). A Pod persists until it is deleted.

The name of a Pod must be a valid [DNS subdomain](https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#dns-subdomain-names) value, but this can produce unexpected results for the Pod hostname. For best compatibility, the name should follow the more restrictive rules for a [DNS label](https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#dns-label-names).

##### Pod OS

1. å¯¹ `.spec.os.name` å­—æ®µçš„ç†è§£

   åœ¨ Pod çš„ YAML ä¸­è®¾ç½® `.spec.os.name` å­—æ®µ**å¹¶ä¸ä¼šå½±å“ `kube-scheduler` (è°ƒåº¦å™¨) çš„å®é™…è°ƒåº¦å†³ç­–**ã€‚å®ƒçš„ä¸»è¦ä½œç”¨æœ‰ä¸¤ç‚¹ï¼š

   1. **å£°æ˜ä¸è¯†åˆ« (Declaration & Identification)**: å®ƒæ˜¯ä¸€ä¸ªæ˜ç¡®çš„å…ƒæ•°æ®å­—æ®µï¼Œç”¨æ¥**å£°æ˜**è¿™ä¸ª Pod å†…çš„å®¹å™¨æ˜¯ä¸ºå“ªä¸ªæ“ä½œç³»ç»Ÿæ„å»ºçš„ï¼ˆç›®å‰æ˜¯ `linux` æˆ– `windows`ï¼‰ã€‚è¿™ä½¿å¾—é›†ç¾¤ä¸­çš„å…¶ä»–ç»„ä»¶æˆ–å·¥å…·ï¼ˆæ¯”å¦‚ç›‘æ§ç³»ç»Ÿã€å®‰å…¨ç­–ç•¥å·¥å…·ï¼‰èƒ½å¤Ÿè½»æ¾è¯†åˆ« Pod çš„æ“ä½œç³»ç»Ÿç±»å‹ã€‚
   2. **ç­–ç•¥åº”ç”¨ (Policy Enforcement)**: å¦‚æ–‡æ¡£ä¸­æåˆ°çš„ï¼Œ`Pod Security Standards` (Pod å®‰å…¨æ ‡å‡†) ä¼šåˆ©ç”¨è¿™ä¸ªå­—æ®µã€‚ä¾‹å¦‚ï¼ŒæŸäº›å®‰å…¨ç­–ç•¥åªé€‚ç”¨äº Linux ç¯å¢ƒï¼ˆæ¯”å¦‚ä¸ `seccomp` æˆ– `AppArmor` ç›¸å…³çš„ç­–ç•¥ï¼‰ï¼Œåœ¨ Windows èŠ‚ç‚¹ä¸Šå¼ºåˆ¶æ‰§è¡Œè¿™äº›ç­–ç•¥æ˜¯æ²¡æœ‰æ„ä¹‰çš„ã€‚é€šè¿‡è¯»å– `.spec.os.name`, ç³»ç»Ÿå¯ä»¥æ™ºèƒ½åœ°é¿å…åœ¨ä¸ç›¸å…³çš„æ“ä½œç³»ç»Ÿä¸Šåº”ç”¨è¿™äº›ç­–ç•¥ã€‚
   3. **é¢å‘æœªæ¥ (Future-proofing)**: ç¤¾åŒºå¯èƒ½åœ¨æœªæ¥çš„ç‰ˆæœ¬ä¸­èµ‹äºˆè¿™ä¸ªå­—æ®µæ›´å¤šçš„åŠŸèƒ½ï¼Œç”šè‡³å¯èƒ½ç›´æ¥å½±å“è°ƒåº¦ã€‚ä½†å°±ç›®å‰è€Œè¨€ï¼Œå®ƒæ›´å¤šçš„æ˜¯ä¸€ä¸ªæè¿°æ€§ã€ä¾›å…¶ä»–ç»„ä»¶æ¶ˆè´¹çš„å­—æ®µã€‚

2. `kubernetes.io/os` Label æ‰“åœ¨å“ªä¸ªèµ„æºä¸Šï¼Ÿ

   `kubernetes.io/os` æ˜¯ä¸€ä¸ª **Node Label** (èŠ‚ç‚¹æ ‡ç­¾)ã€‚å®ƒè¢«æ‰“åœ¨ **Node (èŠ‚ç‚¹)** èµ„æºä¸Šã€‚ä½ å¯ä»¥é€šè¿‡ä»¥ä¸‹å‘½ä»¤æ¥æŸ¥çœ‹ä½ é›†ç¾¤ä¸­æ‰€æœ‰èŠ‚ç‚¹çš„æ ‡ç­¾:

   ```shell
   kubectl get nodes --show-labels
   ```

   > `kubernetes.io/os` è¿™ä¸ªæ ‡ç­¾ä¸»è¦æ˜¯**ç”± `kubelet` è‡ªåŠ¨æ·»åŠ **çš„ã€‚
   >
   > kubectl describe node [your-node-name] çœ‹åˆ°ç›¸åº”çš„System Info

3. åˆ°åº•æ˜¯ä»€ä¹ˆå†³å®šäº† Pod åˆ†é…åˆ°å¯¹åº”çš„æ“ä½œç³»ç»Ÿï¼Ÿ

   çœŸæ­£å†³å®š Pod è¢«è°ƒåº¦åˆ°ç‰¹å®šæ“ä½œç³»ç»ŸèŠ‚ç‚¹ä¸Šçš„æœºåˆ¶ï¼Œæ˜¯ **Pod Spec (Pod è§„çº¦) ä¸­çš„è°ƒåº¦çº¦æŸ**ä¸ **Node (èŠ‚ç‚¹) ä¸Šçš„æ ‡ç­¾**ä¹‹é—´çš„åŒ¹é…ã€‚

   ```yaml
   apiVersion: v1
   kind: Pod
   metadata:
     name: my-windows-pod
   spec:
     # æ­¥éª¤ 1: å£°æ˜ Pod çš„æ“ä½œç³»ç»Ÿç±»å‹
     # è¿™æœ¬èº«ä¸å½±å“è°ƒåº¦ï¼Œä½†æ˜¯ä¸€ä¸ªå¥½ä¹ æƒ¯ï¼Œä¹Ÿä¸ºäº†ç¬¦åˆå®‰å…¨ç­–ç•¥ç­‰ã€‚
     os:
       name: windows
    ...
     nodeSelector:
       kubernetes.io/os: windows
   ```

ä¸ºäº†æ–¹ä¾¿ä½ è®°å¿†ï¼Œæˆ‘ä»¬å¯ä»¥åšä¸€ä¸ªç®€å•çš„ç±»æ¯”ï¼š

| å­—æ®µ/æœºåˆ¶                         | åŠŸèƒ½                   | å¥½æ¯”æ˜¯...                                                    |
| --------------------------------- | ---------------------- | ------------------------------------------------------------ |
| **`.spec.os.name`**               | **å£°æ˜ (Declaration)** | åŒ…è£¹ä¸Šçš„â€œå†…å«ç‰©å“â€æ¸…å•ï¼Œå†™ç€â€œWindows è½¯ä»¶â€ã€‚                 |
| **Node Label `kubernetes.io/os`** | **å±æ€§ (Attribute)**   | æ¯ä¸ªæˆ¿é—¨ä¸Šçš„æ ‡ç­¾ï¼Œå†™ç€â€œæœ¬æˆ·ä½¿ç”¨ Windows ç³»ç»Ÿâ€æˆ–â€œæœ¬æˆ·ä½¿ç”¨ Linux ç³»ç»Ÿâ€ã€‚ |
| **Pod `nodeSelector`**            | **æŒ‡ä»¤ (Instruction)** | å¿«é€’å•ä¸Šçš„â€œæŠ•é€’è¦æ±‚â€ï¼Œæ˜ç¡®æŒ‡ç¤ºï¼šâ€œå¿…é¡»æŠ•é€’åˆ°ä½¿ç”¨ Windows ç³»ç»Ÿçš„ä½æˆ·â€ã€‚ |

##### Pods and controllers

You can use workload resources to create and manage multiple Pods for you.

Here are some examples of workload resources that manage one or more Pods:

- [Deployment](https://kubernetes.io/docs/concepts/workloads/controllers/deployment/)
- [StatefulSet](https://kubernetes.io/docs/concepts/workloads/controllers/statefulset/)
- [DaemonSet](https://kubernetes.io/docs/concepts/workloads/controllers/daemonset)

##### Pod templates

PodTemplates are specifications for creating Pods, and are included in workload resources such as [Deployments](https://kubernetes.io/docs/concepts/workloads/controllers/deployment/), [Jobs](https://kubernetes.io/docs/concepts/workloads/controllers/job/), and [DaemonSets](https://kubernetes.io/docs/concepts/workloads/controllers/daemonset/).  The `PodTemplate` is part of the desired state of whatever workload resource you used to run your app.

the sample:

```yaml
apiVersion: batch/v1
kind: Job
metadata:
  name: hello
spec:
  template:
    # This is the pod template
    spec:
      containers:
      - name: hello
        image: busybox:1.28
        command: ['sh', '-c', 'echo "Hello, Kubernetes!" && sleep 3600']
      restartPolicy: OnFailure
    # The pod template ends here
```

#### Pod update and replacement

Kubernetes doesn't prevent you from managing Pods directly. è™½ç„¶ Kubernetes **å…è®¸** ä½ ç›´æ¥æ“ä½œ Podï¼Œä½†è¿™é€šå¸¸æ˜¯ä¸€ç§**åæ¨¡å¼ï¼ˆanti-patternï¼‰**ï¼Œä¸»è¦ç”¨äºè°ƒè¯•æˆ–ç´§æ€¥æƒ…å†µã€‚

ç”¨edit äº¤äº’å¼å»æ›´æ–°ï¼š`kubectl edit pod [pod-name]` ï¼›è¿˜å¯ä»¥ç”¨patchå»æ›´æ–° `kubectl patch pod my-test-pod -p '{"spec":{"activeDeadlineSeconds":60}}'`

#### Resource sharing and communication

podå†…çš„containerså…±ç”¨ä¸€ä¸ªip, ä¸åŒçš„containerå¦‚æœæƒ³è¦exposeç«¯å£ï¼Œåªèƒ½æ˜¯ä¸åŒçš„ã€‚åŒä¸€podé‡Œé¢çš„containerç”¨localhost+ç«¯å£è¿›è¡Œé€šè®¯

#### Static Pods

æˆ‘ä»¬å¹³æ—¶ç”¨ `kubectl apply -f my-pod.yaml` åˆ›å»ºçš„ Podï¼Œæˆ‘ä»¬ç§°ä¹‹ä¸º**æ ‡å‡† Pod** æˆ– **API Server ç®¡ç†çš„ Pod**ã€‚å®ƒä»¬çš„ç”Ÿå‘½å‘¨æœŸå®Œå…¨ç”± Kubernetes çš„æ§åˆ¶å¹³é¢ï¼ˆç‰¹åˆ«æ˜¯ API Serverï¼‰æ¥ç®¡ç†ã€‚

è€Œ**é™æ€ Pod**åˆ™å®Œå…¨ä¸åŒã€‚

- **å®šä¹‰**ï¼šé™æ€ Pod æ˜¯ç›´æ¥ç”±ç‰¹å®šèŠ‚ç‚¹ä¸Šçš„ **Kubelet** å®ˆæŠ¤è¿›ç¨‹ç®¡ç†çš„ Podï¼Œå®ƒä¸é€šè¿‡ API Server è¿›è¡Œç®¡ç†ã€‚
- **æ¥æº**ï¼šKubelet ä¼šç›‘è§†å…¶æ‰€åœ¨èŠ‚ç‚¹ä¸Šçš„ä¸€ä¸ªç‰¹å®šç›®å½•ï¼ˆé€šå¸¸æ˜¯ `/etc/kubernetes/manifests`ï¼‰ã€‚ä»»ä½•æ”¾åœ¨è¿™ä¸ªç›®å½•ä¸‹çš„æ ‡å‡† Pod å®šä¹‰ YAML/JSON æ–‡ä»¶ï¼Œéƒ½ä¼šè¢« Kubelet è‡ªåŠ¨è¯†åˆ«å¹¶åˆ›å»ºä¸ºé™æ€ Podã€‚
- **ç”Ÿå‘½å‘¨æœŸ**ï¼š
  - **åˆ›å»º**ï¼šå°† Pod çš„ YAML æ–‡ä»¶æ”¾å…¥ Kubelet çš„ç›‘è§†ç›®å½•ã€‚
  - **åˆ é™¤**ï¼šä»è¯¥ç›®å½•ä¸­åˆ é™¤ Pod çš„ YAML æ–‡ä»¶ã€‚
  - **æ›´æ–°**ï¼šä¿®æ”¹è¯¥ç›®å½•ä¸­çš„ Pod YAML æ–‡ä»¶ï¼ˆKubelet ä¼šè‡ªåŠ¨åœæ­¢æ—§çš„ Podï¼Œå¹¶æ ¹æ®æ–°æ–‡ä»¶å¯åŠ¨æ–°çš„ Podï¼‰ã€‚

**é•œåƒ Pod (Mirror Pod)**
ç°åœ¨æˆ‘ä»¬å›åˆ°äº†ä½ é—®é¢˜çš„æ ¸å¿ƒã€‚æ—¢ç„¶é™æ€ Pod ä¸å— API Server ç®¡ç†ï¼Œé‚£æˆ‘ä»¬æ‰§è¡Œ kubectl get pods æ—¶ï¼Œèƒ½çœ‹åˆ°å®ƒä»¬å—ï¼Ÿå¦‚æœçœ‹ä¸åˆ°ï¼Œé‚£é›†ç¾¤ç®¡ç†å‘˜å°±æ— æ³•æ„ŸçŸ¥åˆ°è¿™äº›å…³é”®ç»„ä»¶çš„å­˜åœ¨ï¼Œè¿™ä¼šç»™ç›‘æ§å’Œç®¡ç†å¸¦æ¥éº»çƒ¦ã€‚

* **å®šä¹‰**ï¼šå½“ Kubelet åœ¨èŠ‚ç‚¹ä¸ŠæˆåŠŸåˆ›å»ºäº†ä¸€ä¸ªé™æ€ Pod åï¼Œå®ƒä¼š**è‡ªåŠ¨åœ°**ã€**ä¸»åŠ¨åœ°**åœ¨ API Server ä¸Šä¸ºè¿™ä¸ªé™æ€ Pod åˆ›å»ºä¸€ä¸ªå¯¹åº”çš„ã€**åªè¯»çš„**å¯¹è±¡ã€‚è¿™ä¸ªåœ¨ API Server ä¸Šçš„å¯¹è±¡å°±å«åšâ€œé•œåƒ Podâ€ã€‚
* **ç›®çš„**ï¼šå®ƒçš„å”¯ä¸€ç›®çš„å°±æ˜¯è®©è¿™ä¸ªé™æ€ Pod åœ¨ Kubernetes çš„ API ä¸­**å¯è§ (Visible)**ã€‚

#### Pods with multiple containers

For example, you might have a container that acts as a web server for files in a shared volume, and a separate [sidecar container](https://kubernetes.io/docs/concepts/workloads/pods/sidecar-containers/) that updates those files from a remote source, as in the following diagram:

![image-20250919162927803](./images/image-20250919162927803.png)



#### Pod Lifecycle

 Pods follow a defined lifecycle, starting in the `Pending` [phase](https://kubernetes.io/docs/concepts/workloads/pods/pod-lifecycle/#pod-phase), moving through `Running` if at least one of its primary containers starts OK, and then through either the `Succeeded` or `Failed` phases depending on whether any container in the Pod terminated in failure.

##### Pod lifetime

Pods are only [scheduled](https://kubernetes.io/docs/concepts/scheduling-eviction/) once in their lifetime; assigning a Pod to a specific node is called *binding*, and the process of selecting which node to use is called *scheduling*. 

You can use [Pod Scheduling Readiness](https://kubernetes.io/docs/concepts/scheduling-eviction/pod-scheduling-readiness/) to delay scheduling for a Pod until all its *scheduling gates* are removed. For example, you might want to define a set of Pods but only trigger scheduling once all the Pods have been created.

> å¯ä»¥å®šä¹‰ä¸åŒçš„è°ƒåº¦é—¨ï¼Œåœ¨çœŸçš„è¢«scheduleä¹‹å‰éœ€è¦ç›¸å°±çš„controller è¢«è¿™äº›è°ƒåº¦é—¨éƒ½åˆ é™¤

##### Pods and fault recovery

ä¸ä¼šæŠŠé‚£ä¸ªæ—§çš„ã€å¤±è´¥çš„ Pod å®ä¾‹ï¼ˆidentified by a UIDï¼‰æ‹¿èµ·æ¥ï¼Œæ‹æ‹ç°å°˜ï¼Œç„¶åæ”¾åˆ°ä¸€ä¸ªæ–°èŠ‚ç‚¹ä¸Šè®©å®ƒç»§ç»­è¿è¡Œã€‚æˆ‘ä»¬æ˜¯ç›´æ¥æ”¾å¼ƒæ—§çš„ï¼Œç„¶åç”±åƒ Deployment è¿™æ ·çš„æ§åˆ¶å™¨åˆ›å»ºä¸€ä¸ªå…¨æ–°çš„æ›¿ä»£å“ï¼Œè¿™ä¸ªæ›¿ä»£å“å†ç”±è°ƒåº¦å™¨æ‰¾ä¸€ä¸ªæ–°å®¶ã€‚

nodeæ•…éšœ vs Pod æ•…éšœï¼š

| ç‰¹æ€§               | åœºæ™¯ 1: èŠ‚ç‚¹å®•æœº (Node Failure)        | åœºæ™¯ 2: Pod æ•…éšœ (Pod Failure on Healthy Node) |
| ------------------ | -------------------------------------- | ---------------------------------------------- |
| **ä¸»è¦å¤„ç†è€…**     | `kube-controller-manager` (åœ¨æ§åˆ¶å¹³é¢) | `kubelet` (åœ¨å·¥ä½œèŠ‚ç‚¹ä¸Š)                       |
| **å¤„ç†å¯¹è±¡**       | æ•´ä¸ª **Pod å¯¹è±¡**                      | Pod å†…éƒ¨çš„**å®¹å™¨ (Container)**                 |
| **ç»“æœ**           | æ—§ Pod è¢«é©±é€/åˆ é™¤ï¼›**åˆ›å»ºå…¨æ–°çš„ Pod** | **åœ¨åŒä¸€ä¸ª Pod å†…é‡å¯å®¹å™¨**                    |
| **Pod UID**        | æ›¿ä»£å“çš„ UID æ˜¯**æ–°çš„**                | Pod çš„ UID **ä¿æŒä¸å˜**                        |
| **Pod IP åœ°å€**    | æ›¿ä»£å“çš„ IP åœ°å€æ˜¯**æ–°çš„**             | Pod çš„ IP åœ°å€**ä¿æŒä¸å˜**                     |
| **æ‰€åœ¨èŠ‚ç‚¹**       | æ›¿ä»£å“è¢«è°ƒåº¦åˆ°**æ–°çš„å¥åº·èŠ‚ç‚¹**ä¸Š       | ä»ç„¶åœ¨**åŸæ¥çš„èŠ‚ç‚¹**ä¸Š                         |
| **æ¢å¤é€Ÿåº¦**       | è¾ƒæ…¢ (åˆ†é’Ÿçº§åˆ«ï¼Œæœ‰ 5 åˆ†é’Ÿç­‰å¾…æœŸ)       | éå¸¸å¿« (ç§’çº§)                                  |
| **`kubectl` è¡¨ç°** | æ—§ Pod æ¶ˆå¤±ï¼Œæ–° Pod å‡ºç°               | åŒä¸€ä¸ª Pod çš„ `RESTARTS` è®¡æ•°å¢åŠ               |

##### Associated lifetimes

When something is said to have the same lifetime as a Pod, such as a [volume](https://kubernetes.io/docs/concepts/storage/volumes/), that means that the thing exists as long as that specific Pod (with that exact UID) exists. 

![image-20250919162927803](./images/image-20250919162927803.png)

è¿™ä¸ªmulti-container Pod ä¸€æ—¦ç»“æŸç”Ÿå‘½ï¼Œé‚£ä¹ˆæ‰€å…³è”çš„Volumeä¹Ÿå°†ç»“æŸã€‚

##### Pod phase

Here are the possible values for `phase`:

| Value       | Description                                                  |
| :---------- | :----------------------------------------------------------- |
| `Pending`   | The Pod has been accepted by the Kubernetes cluster, but one or more of the containers has not been set up and made ready to run. This includes time a Pod spends waiting to be scheduled as well as the time spent downloading container images over the network. |
| `Running`   | The Pod has been bound to a node, and all of the containers have been created. At least one container is still running, or is in the process of starting or restarting. |
| `Succeeded` | All containers in the Pod have terminated in success, and will not be restarted. |
| `Failed`    | All containers in the Pod have terminated, and at least one container has terminated in failure. That is, the container either exited with non-zero status or was terminated by the system, and is not set for automatic restarting. |
| `Unknown`   | For some reason the state of the Pod could not be obtained. This phase typically occurs due to an error in communicating with the node where the Pod should be running. |

> Make sure not to confuse *Status*, a kubectl display field for user intuition, with the pod's `phase`.  When a pod is failing to start repeatedly, `CrashLoopBackOff` may appear in the `Status` field of some kubectl commands. Similarly, when a pod is being deleted, `Terminating` may appear in the `Status` field of some kubectl commands.

> **Kubernetes Pod ç»ˆæ­¢ç”Ÿå‘½å‘¨æœŸ (v1.27+) æ ¸å¿ƒçŸ¥è¯†ç‚¹**
>
> **1. æ ¸å¿ƒå˜åŒ–ï¼š**
>
> - è‡ª K8s v1.27 èµ·ï¼Œè¢«åˆ é™¤çš„ Pod ä¸ä¼šä» `Terminating` çŠ¶æ€ç›´æ¥æ¶ˆå¤±ã€‚
> - å®ƒä¼šå…ˆæ ¹æ®å®¹å™¨çš„æœ€ç»ˆé€€å‡ºç ï¼Œè¿‡æ¸¡åˆ°ä¸€ä¸ªæ˜ç¡®çš„**ç»ˆç«¯é˜¶æ®µ**ï¼š`Succeeded` (æ‰€æœ‰å®¹å™¨é€€å‡ºç ä¸º0) æˆ– `Failed` (è‡³å°‘ä¸€ä¸ªå®¹å™¨é€€å‡ºç é0)ã€‚
> - **ç›®çš„**ï¼šæå¤§å¢å¼ºäº† Pod çš„**å¯è§‚æµ‹æ€§**ï¼Œæ–¹ä¾¿å‡†ç¡®è¿½è¸ªä¸€æ¬¡æ€§ä»»åŠ¡ï¼ˆå¦‚ Jobï¼‰çš„æœ€ç»ˆæˆè´¥ã€‚
>
> **2. â€œç»ˆç«¯é˜¶æ®µâ€åœç•™æ—¶é•¿ç”±è°å†³å®šï¼Ÿ**
>
> è¿™ä¸ªåœç•™æ—¶é—´ç”±ä¸¤ç§æœºåˆ¶æ§åˆ¶ï¼Œ**ä¼˜å…ˆçº§ä»é«˜åˆ°ä½**ï¼š
>
> - **æœºåˆ¶ä¸€ (ç²¾ç¡®æ§åˆ¶ - æ¨è): `ttlSecondsAfterFinished`**
>   - **é…ç½®**: åœ¨ Pod æˆ– Job çš„ `spec` ä¸­è®¾ç½® `ttlSecondsAfterFinished: <ç§’æ•°>`ã€‚
>   - **è¡Œä¸º**: Pod åˆ°è¾¾ `Succeeded`/`Failed` çŠ¶æ€åï¼Œä¼š**ç²¾ç¡®åœ°**ç­‰å¾…æŒ‡å®šçš„ç§’æ•°ï¼Œç„¶åè¢«åƒåœ¾å›æ”¶æœºåˆ¶è‡ªåŠ¨åˆ é™¤ã€‚
>   - **ç¤ºä¾‹**: è®¾ç½®ä¸º `100` åˆ™ä¿ç•™100ç§’ï¼›è®¾ç½®ä¸º `0` åˆ™ä¼šç«‹å³æ¸…ç†ã€‚
> - **æœºåˆ¶äºŒ (é›†ç¾¤å…œåº• - ä¸ç²¾ç¡®): `terminated-pod-gc-threshold`**
>   - **è§¦å‘æ¡ä»¶**: ä»…å½“ Pod **æœªè®¾ç½®** `ttlSecondsAfterFinished` æ—¶æ­¤æœºåˆ¶æ‰ç”Ÿæ•ˆã€‚
>   - **è¡Œä¸º**: ç”±é›†ç¾¤æ§åˆ¶å¹³é¢ (`kube-controller-manager`) çš„å…¨å±€å‚æ•° `--terminated-pod-gc-threshold` æ§åˆ¶ã€‚åªæœ‰å½“é›†ç¾¤ä¸­å·²ç»ˆæ­¢çš„ Pod æ€»æ•°è¶…è¿‡æ­¤é˜ˆå€¼æ—¶ï¼Œæ‰ä¼šå¼€å§‹æ¸…ç†æœ€æ—§çš„ Podã€‚
>   - **ç»“è®º**: åœç•™æ—¶é—´**ä¸ç¡®å®š**ï¼Œå¯èƒ½éå¸¸ä¹…ã€‚
>
> **3. æœ€ä½³å®è·µï¼š** ä¸ºäº†å¯é¢„æµ‹åœ°ç®¡ç† Pod ç”Ÿå‘½å‘¨æœŸå¹¶ä¿æŒé›†ç¾¤æ•´æ´ï¼Œåº”å§‹ç»ˆä¸ºä½ çš„ä¸€æ¬¡æ€§ä»»åŠ¡ï¼ˆå°¤å…¶æ˜¯ `Job` èµ„æºï¼‰**æ˜ç¡®è®¾ç½® `spec.ttlSecondsAfterFinished`**ã€‚

##### Container states 

