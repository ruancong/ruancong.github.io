<!doctype html>
<html lang="en-US">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width,initial-scale=1" />
    <meta name="generator" content="VuePress 2.0.0-rc.19" />
    <style>
      :root {
        --vp-c-bg: #fff;
      }

      [data-theme='dark'] {
        --vp-c-bg: #1b1b1f;
      }

      html,
      body {
        background-color: var(--vp-c-bg);
      }
    </style>
    <script>
      const userMode = localStorage.getItem('vuepress-color-scheme')
      const systemDarkMode =
        'matchMedia' in window
          ? window.matchMedia('(prefers-color-scheme: dark)').matches
          : false

      if (userMode === 'light') {
        document.documentElement.dataset.theme = 'light'
      } else if (userMode === 'dark' || systemDarkMode) {
        document.documentElement.dataset.theme = 'dark'
      }
    </script>
    <link rel="icon" href="/images/logo.svg"><title>Notes</title><meta name="description" content="Daily Learning Notes">
    <link rel="preload" href="/assets/style-CMopnafn.css" as="style"><link rel="stylesheet" href="/assets/style-CMopnafn.css">
    <link rel="modulepreload" href="/assets/app-DXTNhLx0.js"><link rel="modulepreload" href="/assets/k8s.html-BxL5FEWF.js">
    <link rel="prefetch" href="/assets/index.html-D5oMLDmf.js" as="script"><link rel="prefetch" href="/assets/commands.html-CMen2O7f.js" as="script"><link rel="prefetch" href="/assets/linux.html-DLDvj2Ev.js" as="script"><link rel="prefetch" href="/assets/MinIO.html-BApGlak-.js" as="script"><link rel="prefetch" href="/assets/PostgreSQL.html-BqtDnx0A.js" as="script"><link rel="prefetch" href="/assets/docker.html-CuyB22K8.js" as="script"><link rel="prefetch" href="/assets/forget-lock-psw.html-COfdRxPK.js" as="script"><link rel="prefetch" href="/assets/raft.html-hHPwjYja.js" as="script"><link rel="prefetch" href="/assets/split-brain.html-CplNHAUs.js" as="script"><link rel="prefetch" href="/assets/network-basis.html-CFy1JVA4.js" as="script"><link rel="prefetch" href="/assets/问题解决.html-CeJ56pMD.js" as="script"><link rel="prefetch" href="/assets/English-Grammar.html-Dnjvd8ai.js" as="script"><link rel="prefetch" href="/assets/英语句子解析.html-fyA78QJU.js" as="script"><link rel="prefetch" href="/assets/语法学习.html-aNXkIQR9.js" as="script"><link rel="prefetch" href="/assets/template.html-ClQOUEIC.js" as="script"><link rel="prefetch" href="/assets/nextjs.html-CN36F46N.js" as="script"><link rel="prefetch" href="/assets/react-router.html-DhM73FN-.js" as="script"><link rel="prefetch" href="/assets/react.html-CD0sZZ5T.js" as="script"><link rel="prefetch" href="/assets/spingboot-3.x.html-BmxYpvXE.js" as="script"><link rel="prefetch" href="/assets/05-20.html-DKlRs5xE.js" as="script"><link rel="prefetch" href="/assets/05-21.html-C5ZpFoZN.js" as="script"><link rel="prefetch" href="/assets/05-22.html-DkwcrvDW.js" as="script"><link rel="prefetch" href="/assets/05-23.html-Bel__BCV.js" as="script"><link rel="prefetch" href="/assets/02-26.html-BidzYPMa.js" as="script"><link rel="prefetch" href="/assets/01-03.html-CMdjP-l2.js" as="script"><link rel="prefetch" href="/assets/01-08.html-yTwzmngV.js" as="script"><link rel="prefetch" href="/assets/01-10.html-nz8eqxw_.js" as="script"><link rel="prefetch" href="/assets/01-15.html-B22V5HmD.js" as="script"><link rel="prefetch" href="/assets/07-09.html-DaYPsUPf.js" as="script"><link rel="prefetch" href="/assets/07-10.html-JGDKKhtW.js" as="script"><link rel="prefetch" href="/assets/07-11.html-BAtimu0h.js" as="script"><link rel="prefetch" href="/assets/07-12.html-R946u9H5.js" as="script"><link rel="prefetch" href="/assets/07-13.html-BcpVoWyu.js" as="script"><link rel="prefetch" href="/assets/07-14.html-BTRGN_RW.js" as="script"><link rel="prefetch" href="/assets/07-15.html-Cqiu1Nv5.js" as="script"><link rel="prefetch" href="/assets/07-16.html-DmhNZabU.js" as="script"><link rel="prefetch" href="/assets/09-03.html-KuHwJhyl.js" as="script"><link rel="prefetch" href="/assets/404.html-BclxKMBT.js" as="script"><link rel="prefetch" href="/assets/VocabularyAudio-DsF-nr3y.js" as="script"><link rel="prefetch" href="/assets/setupDevtools-7MC2TMWH-BmsRFWiU.js" as="script">
  </head>
  <body>
    <div id="app"><!--[--><div class="vp-theme-container external-link-icon" vp-container><!--[--><header class="vp-navbar" vp-navbar><div class="vp-toggle-sidebar-button" title="toggle sidebar" aria-expanded="false" role="button" tabindex="0"><div class="icon" aria-hidden="true"><span></span><span></span><span></span></div></div><span><a class="route-link" href="/"><img class="vp-site-logo" src="/images/logo.svg" alt="Notes"><span class="vp-site-name vp-hide-mobile" aria-hidden="true">Notes</span></a></span><div class="vp-navbar-items-wrapper" style=""><!--[--><!--]--><nav class="vp-navbar-items vp-hide-mobile" aria-label="site navigation"><!--[--><div class="vp-navbar-item"><a class="route-link auto-link" href="/" aria-label="首页"><!---->首页<!----></a></div><div class="vp-navbar-item"><a class="auto-link external-link" href="https://github.com/ruancong/ruancong.github.io" aria-label="GitHub" rel="noopener noreferrer" target="_blank"><!---->GitHub<!----></a></div><!--]--></nav><!--[--><!--]--><button type="button" class="vp-toggle-color-mode-button" title="toggle color mode"><svg class="light-icon" viewbox="0 0 32 32" style=""><path d="M16 12.005a4 4 0 1 1-4 4a4.005 4.005 0 0 1 4-4m0-2a6 6 0 1 0 6 6a6 6 0 0 0-6-6z" fill="currentColor"></path><path d="M5.394 6.813l1.414-1.415l3.506 3.506L8.9 10.318z" fill="currentColor"></path><path d="M2 15.005h5v2H2z" fill="currentColor"></path><path d="M5.394 25.197L8.9 21.691l1.414 1.415l-3.506 3.505z" fill="currentColor"></path><path d="M15 25.005h2v5h-2z" fill="currentColor"></path><path d="M21.687 23.106l1.414-1.415l3.506 3.506l-1.414 1.414z" fill="currentColor"></path><path d="M25 15.005h5v2h-5z" fill="currentColor"></path><path d="M21.687 8.904l3.506-3.506l1.414 1.415l-3.506 3.505z" fill="currentColor"></path><path d="M15 2.005h2v5h-2z" fill="currentColor"></path></svg><svg class="dark-icon" viewbox="0 0 32 32" style="display:none;"><path d="M13.502 5.414a15.075 15.075 0 0 0 11.594 18.194a11.113 11.113 0 0 1-7.975 3.39c-.138 0-.278.005-.418 0a11.094 11.094 0 0 1-3.2-21.584M14.98 3a1.002 1.002 0 0 0-.175.016a13.096 13.096 0 0 0 1.825 25.981c.164.006.328 0 .49 0a13.072 13.072 0 0 0 10.703-5.555a1.01 1.01 0 0 0-.783-1.565A13.08 13.08 0 0 1 15.89 4.38A1.015 1.015 0 0 0 14.98 3z" fill="currentColor"></path></svg></button><!----></div></header><!--]--><div class="vp-sidebar-mask"></div><!--[--><aside class="vp-sidebar" vp-sidebar><nav class="vp-navbar-items" aria-label="site navigation"><!--[--><div class="vp-navbar-item"><a class="route-link auto-link" href="/" aria-label="首页"><!---->首页<!----></a></div><div class="vp-navbar-item"><a class="auto-link external-link" href="https://github.com/ruancong/ruancong.github.io" aria-label="GitHub" rel="noopener noreferrer" target="_blank"><!---->GitHub<!----></a></div><!--]--></nav><!--[--><!--]--><ul class="vp-sidebar-items"><!--[--><li><p tabindex="0" class="vp-sidebar-item vp-sidebar-heading"> <!----></p><!----></li><!--]--></ul><!--[--><!--]--></aside><!--]--><!--[--><main class="vp-page"><!--[--><!--]--><div vp-content><!--[--><!--]--><div><h2 id="kubernetes-components" tabindex="-1"><a class="header-anchor" href="#kubernetes-components"><span>Kubernetes Components</span></a></h2><p>The components of a Kubernetes cluster:</p><p><img src="/assets/image-20250815091851689-BttBua7w.png" alt="image-20250815091851689"></p><h2 id="官方文档笔记" tabindex="-1"><a class="header-anchor" href="#官方文档笔记"><span>官方文档笔记</span></a></h2><ul><li><p>Pods are the smallest deployable units of computing that you can create and manage in Kubernetes</p></li><li><p>You don&#39;t need to run multiple containers to provide replication (for resilience or capacity)</p></li><li><p>Restarting a container in a Pod should not be confused with restarting a Pod. A Pod is not a process, but an environment for running container(s). A Pod persists until it is deleted.</p></li><li><p>Modifying the pod template or switching to a new pod template has no direct effect on the Pods that already exist.</p><blockquote><p>只会根据新的更新的模板重新创建一个pod</p></blockquote></li><li><p>The name of a Pod must be a valid DNS subdomain value, but this can produce unexpected results for the Pod hostname. For best compatibility, the name should follow the more restrictive rules for a DNS label</p></li><li><p>Deployment：负责管理和维护你的应用实例（Pod）。它会确保指定数量的 Nginx Pod 正在运行。如果某个 Pod 挂掉了，Deployment 会自动创建一个新的来替代它</p></li><li><p>Service：负责为一组 Pod 提供一个稳定、统一的访问入口。因为 Pod 是“短暂”的，它们的 IP 地址会变化。Service 提供了一个固定的 IP 地址和 DNS 名称，使得其他应用或外部用户可以方便地访问到你的 Nginx 服务，而无需关心后端具体是哪个 Pod 在提供服务。</p></li><li><p>你可以把 app: nginx 理解为你和 Kubernetes 的一个约定：你给一组 Pod 贴上这个独特的“名牌”，然后告诉 Deployment 和 Service 按照这个“名牌”去认领和查找它们</p></li><li><p>Most often, you provide the information to kubectl in a file known as a manifest. By convention, manifests are YAML ( you could also use JSON format).</p></li><li><p>YAML 文件在两种模式下的“角色”</p><ul><li>在 kubectl create -f (命令式) 中：YAML 文件是一个一次性的模板。你命令 Kubernetes：“按照这个模板，给我创建一个对象”。创建完成后，这个 YAML 文件和集群中的那个对象之间，就没有必然的联系了。Kubernetes 不会“记住”你是用哪个文件创建的它。</li><li>在 kubectl apply -f (声明式) 中：YAML 文件是对象的**“期望状态”的声明**。你告诉 Kubernetes：“请确保集群中有一个与这个 YAML 文件描述的状态相匹配的对象”。Kubernetes 不仅会创建这个对象，还会记录下这个“期望状态”，以便于未来的比较和更新。</li></ul></li><li><p>仅仅修改并保存在本地 configs/ 目录下的 YAML 文件，并不会对集群产生任何影响。 Kubernetes 集群完全不知道你本地文件的变化。你必须通过 kubectl apply 这个动作，明确地告诉 Kubernetes：“请按照我最新的配置文件，去同步集群的状态。”</p></li><li><p>仅仅修改并保存在本地 configs/ 目录下的 YAML 文件，并不会对集群产生任何影响。 Kubernetes 集群完全不知道你本地文件的变化。你必须通过 kubectl apply 这个动作，明确地告诉 Kubernetes：“请按照我最新的配置文件，去同步集群的状态。”</p><div class="language-bash line-numbers-mode" data-highlighter="prismjs" data-ext="sh" data-title="sh"><pre><code><span class="line"> kubectl <span class="token function">diff</span> <span class="token parameter variable">-f</span> configs/</span>
<span class="line"></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div></div></div></li><li><p>Our previous example (replicas): The change from kubectl scale was NOT retained because the replicas field was &quot;owned&quot; by your YAML file. apply enforced your file&#39;s value.</p></li><li><p>The note&#39;s meaning (LoadBalancer example): Changes from other controllers (like adding a clusterIP) ARE retained because those fields are not &quot;owned&quot; by your YAML file. The patch mechanism surgically updates only the fields you explicitly manage in your file.</p></li><li><p>Starting with Kubernetes v1.25, the API server offers server side field validation that detects unrecognized or duplicate fields in an object. It provides all the functionality of kubectl --validate on the server side.</p><blockquote><p><strong>服务端试运行 (Server-side Dry Run)</strong></p><div class="language-bash line-numbers-mode" data-highlighter="prismjs" data-ext="sh" data-title="sh"><pre><code><span class="line">kubectl apply <span class="token parameter variable">-f</span> <span class="token punctuation">[</span>your-manifest<span class="token punctuation">]</span>.yaml --dry-run<span class="token operator">=</span>server</span>
<span class="line"></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div></div></div><p>如果文件有错误，它会像上面的例子一样报错。如果文件格式正确，它会返回一个成功的提示（但不会真的创建资源）。<strong>总之，--dry-run=server 是一个非常安全的验证工具。</strong> 它的设计初衷就是为了让您在真正部署到集群之前，百分之百确认您的配置清单是有效且被集群所接受的，而无需担心会意外创建或修改任何东西。</p></blockquote></li><li><p>When you create an object in Kubernetes, you must provide the object spec that describes its desired state, as well as some basic information about the object (such as a name).</p></li><li><p>Almost every Kubernetes object includes two nested object fields that govern the object&#39;s configuration: the object spec and the object status.</p></li><li><p>The status describes the current state of the object, supplied and updated by the Kubernetes system and its components.</p><blockquote><p>status可以理解为“看起来是什么样”，而state是“实际是什么样子的”</p></blockquote></li><li><p>Each object in your cluster has a Name that is unique for that type of resource. Every Kubernetes object also has a UID that is unique across your whole cluster.</p><blockquote><p>For example, you can only have one Pod named <code>myapp-1234</code> within the same namespace, but you can have one Pod and one Deployment that are each named <code>myapp-1234</code>.</p></blockquote></li><li><p><strong>Kubernetes 的世界观是建立在它自己的 API 对象上的</strong>。它通过 Kubelet 等组件来观测外部物理世界的状态，并尽力使其与内部的声明式状态保持一致。但如果外部世界发生了它无法观测到的剧烈变化（比如一个节点被偷偷替换了），而内部的逻辑对象没有被相应更新，就会导致这种“身份混淆”和状态不一致，从而引发各种难以排查的诡异问题。</p><blockquote><p>在物理/虚拟层面销毁一个节点之前，<strong>务必先在 Kubernetes 中将其删除</strong>。</p><p>正确的操作流程应该是：</p><ol><li><p><strong>标记节点不可调度</strong>：</p><div class="language-bash line-numbers-mode" data-highlighter="prismjs" data-ext="sh" data-title="sh"><pre><code><span class="line">kubectl cordon worker-01</span>
<span class="line"></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div></div></div><p>这能防止新的 Pod 被调度到该节点上。</p></li><li><p><strong>驱逐节点上的所有 Pod</strong>：</p><div class="language-bash line-numbers-mode" data-highlighter="prismjs" data-ext="sh" data-title="sh"><pre><code><span class="line">kubectl drain worker-01 --ignore-daemonsets</span>
<span class="line"></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div></div></div><p>这会安全地将该节点上现有的 Pod 迁移到其他节点。<code>--ignore-daemonsets</code> 是因为 DaemonSet 管理的 Pod 不需要被驱逐。</p></li><li><p><strong>从 Kubernetes 中删除节点对象</strong>：</p><div class="language-bash line-numbers-mode" data-highlighter="prismjs" data-ext="sh" data-title="sh"><pre><code><span class="line">kubectl delete <span class="token function">node</span> worker-01</span>
<span class="line"></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div></div></div><p>这一步就是“销毁学籍卡”，彻底清除它在 Kubernetes 中的所有记录。</p></li><li><p><strong>销毁物理/虚拟机</strong>： 现在，你可以安全地去你的云平台或虚拟化平台删除这台服务器了。</p></li></ol></blockquote></li><li><p>A client-provided string that refers to an object in a <a href="https://kubernetes.io/docs/reference/using-api/api-concepts/#standard-api-terminology" target="_blank" rel="noopener noreferrer">resource</a> URL, such as <code>/api/v1/pods/some-name</code>.</p><p>Only one object of a given kind can have a given name at a time. Names must be unique across <strong>all API versions</strong> of the same resource. API resources are distinguished by their API group, resource type, namespace (for namespaced resources), and name. In other words, API version is irrelevant in this context.</p></li><li><p>在 Deployment（以及 ReplicaSet, StatefulSet, Job, CronJob 等这类控制器）的 Pod 模板（spec.template）中，metadata.name 这个字段是不能设置的。如果你尝试设置它，Kubernetes API Server 会拒绝你的请求。</p></li><li><p><code>kind: Ingress</code> 会暴露一个 IP 地址吗？</p><blockquote><p>不会，<code>Ingress</code> 资源本身不会。一个 <code>kind: Ingress</code> 的 YAML 文件，它仅仅是<strong>一套规则</strong>的集合，就像一张写着“<code>a.com</code> 的流量请走A门，<code>b.com</code> 的流量请走B门”的说明书。这张说明书本身并没有地址，它需要被人（也就是 <code>Ingress Controller</code>）去阅读和执行。</p><p>真正暴露 IP 地址的，是 <code>Ingress Controller</code> 的 <code>Service</code>！</p><p>回顾一下 <code>Ingress Controller</code> 是如何被安装的：</p><ol><li><strong>Ingress Controller 是一个需要被</strong><code>安装</code><strong>到集群中的应用</strong>，它不是 K8s 自带的。</li><li><strong>安装的本质</strong>是应用一套包含了 <code>Deployment</code>、<code>Service</code>、<code>RBAC</code> 等资源的 YAML 文件。</li><li><strong>K3s 用户最幸福</strong>，因为 K3s 已经内置了 <strong>Traefik</strong>，无需手动安装。你只需要直接在 <code>Ingress</code> 中使用 <code>ingressClassName: &quot;traefik&quot;</code> 即可。</li><li>在<strong>标准 K8s 环境</strong>中，最常用的选择是 <strong>NGINX Ingress Controller</strong>，可以通过官方 <code>kubectl apply</code> 命令或 <code>Helm</code> Chart 来安装。</li><li><strong><code>IngressClass</code> 资源是在安装 Controller 的过程中被自动创建的</strong>。它像一个“告示牌”，告诉整个集群：“嘿，我这里有一个名为 <code>nginx</code> (或 <code>traefik</code>) 的 Controller，你们谁需要处理 Ingress 规则，就通过 <code>ingressClassName</code> 来找我！”</li></ol><p>现在，<code>Ingress</code> (规则)、<code>Ingress Controller</code> (执行者) 和 <code>IngressClass</code> (联系方式) 这三者之</p><p>它通常包含一个 <code>Deployment</code> (运行 Controller 的 Pods) 和一个 <code>Service</code> (把这些 Pods 暴露出去)。这个 <code>Service</code> 的类型通常是 <code>LoadBalancer</code> 或 <code>NodePort</code>。</p><ul><li>当 <code>Service</code> 的类型是 <code>LoadBalancer</code> 时，云服务商会为<strong>这个 Service</strong>分配一个<strong>公网 IP 地址</strong>。</li><li>当 <code>Service</code> 的类型是 <code>NodePort</code> 时，你可以通过<strong>任何一个节点的 IP</strong> + <code>NodePort</code> 端口来访问。</li></ul><p>那个宝贵的、唯一的、对外服务的公网 IP 地址，是属于 <strong>Ingress Controller 的 Service</strong> 的，而不是属于你创建的某一个 <code>Ingress</code> 规则对象的。</p><p>你可以通过以下命令查看到这个 IP 地址：</p><div class="language-bash line-numbers-mode" data-highlighter="prismjs" data-ext="sh" data-title="sh"><pre><code><span class="line"><span class="token comment"># 查看 Ingress Controller 的 Service</span></span>
<span class="line"><span class="token comment"># 注意命名空间，如果你是用 helm 装的 nginx-ingress，那就在 ingress-nginx 命名空间</span></span>
<span class="line"><span class="token comment"># 如果是 k3s 自带的 traefik，那就在 kube-system</span></span>
<span class="line">kubectl get <span class="token function">service</span> <span class="token parameter variable">-n</span> ingress-nginx </span>
<span class="line"></span>
<span class="line"><span class="token comment"># 你会看到类似这样的输出</span></span>
<span class="line"><span class="token comment"># NAME                       TYPE           CLUSTER-IP      EXTERNAL-IP      PORT(S)                      AGE</span></span>
<span class="line"><span class="token comment"># ingress-nginx-controller   LoadBalancer   10.43.151.108   203.0.113.55     80:32168/TCP,443:30256/TCP   10m</span></span>
<span class="line"><span class="token comment">#                                                          ^^^^^^^^^^^^</span></span>
<span class="line"><span class="token comment">#                                                          就是这个 IP！</span></span>
<span class="line"></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div></blockquote></li><li><p>kubectl 默认会在你的用户主目录下的 .kube 文件夹中寻找名为 config 的文件。</p><blockquote><p>在 Linux 和 macOS 上，路径通常是 ~/.kube/config。</p></blockquote></li><li><p>在生产环境中，通常会有多个 Master 节点（在 k3d/k3s 里被称为 Server 节点）来确保高可用性。你不会直接连接到某一个 Master 节点，因为如果那个节点宕机了，你就无法访问集群了。正确的做法是连接到一个<strong>负载均衡器 (Load Balancer)</strong>，由它来将你的请求转发给后面健康的 Master 节点。</p><p>k3d 在本地用 Docker 容器巧妙地复现了这套架构：</p><ol><li><strong><code>k3d-my-cluster-server-0</code> 容器</strong>: 这是真正的 K3s Server，它在<strong>容器内部</strong>运行着 Kubernetes API Server，监听着 <code>6443</code> 端口。这个容器没有直接暴露端口到宿主机，所以你从外部无法直接访问它。</li><li><strong><code>k3d-my-cluster-serverlb</code> 容器</strong>: 这是一个基于 NGINX 的反向代理/负载均衡器。k3d 启动它，并让它监听宿主机的一个端口，然后将流量转发给后端的 K3s Server 容器。</li></ol></li><li><p>你的 kubectl 并不是直接和 K3s Server 容器通信。它在和一个作为负载均衡器的代理容器 (k3d-my-cluster-serverlb) 通信。这个代理容器负责将你的请求安全地转发给真正的 K3s Server 容器。39753 是 k3d 为这个负载均衡器随机选择的、暴露在你宿主机上的端口。</p></li><li><p>故障排查三步法</p><blockquote><p>第 1 步：确认 Pods 是否健康运行</p><div class="language-bash line-numbers-mode" data-highlighter="prismjs" data-ext="sh" data-title="sh"><pre><code><span class="line">kubectl get pods <span class="token parameter variable">-o</span> wide</span>
<span class="line"></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div></div></div><p>第 2 步：确认 Service 是否正确关联了 Pods</p><div class="language-bash line-numbers-mode" data-highlighter="prismjs" data-ext="sh" data-title="sh"><pre><code><span class="line">kubectl describe <span class="token function">service</span> nginx-service</span>
<span class="line"></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div></div></div><p><strong>正确的状态</strong>: <code>Endpoints</code> 后面应该列出了一个或多个 IP 地址和端口，这些 IP 应该与你在上一步中看到的 Pod IP 完全一致。<code>Endpoints: 10.42.0.5:80,10.42.0.6:80</code></p><p>第 3 步：确认 k3d 节点的端口映射 (最可能的原因)</p></blockquote></li><li><p>最快、最直接的绕过网络问题的方法，我们在上次讨论中也提到了。它不依赖任何端口映射，而是直接在你的电脑和 Service 之间建立一条隧道。</p><blockquote><div class="language-bash line-numbers-mode" data-highlighter="prismjs" data-ext="sh" data-title="sh"><pre><code><span class="line"><span class="token comment"># 在新终端中运行</span></span>
<span class="line">kubectl port-forward service/nginx-service <span class="token number">8080</span>:80</span>
<span class="line"></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div></div></div></blockquote></li><li><p>在k3d里测试时，设置type=LoadBalancer时没有用，即使设置k3d cluster create my-cluster -p &quot;8080:80@loadbalancer&quot;， 需要映射type=NodePort 的端口，如8080:30080</p></li><li><p>Service <code>type</code> 是 <code>ClusterIP</code>【默认值】时ip不直接暴露到集群外部，只能被集群内的 Ingress 控制器找到。type为loadBalancer时, 端口会暴露到集群外。【在k3d中测试时，把service的type设置为loadBalance并不生效】</p></li></ul><blockquote><p><code>LoadBalancer</code> 类型是 <code>NodePort</code> 的扩展。它会向底层云平台（如 AWS, GCP, Azure）请求一个外部负载均衡器，并将这个负载均衡器的 IP 地址作为 Service 的外部访问入口。</p><ul><li><strong>作用</strong>：这是将服务暴露到公网的 <strong>标准方式</strong>。云服务提供商会为你创建一个负载均衡器，并将流量导向你所有节点的 <code>NodePort</code>。</li><li><strong>使用场景</strong>：适用于生产环境，当你需要一个稳定、高可用的公网 IP 来暴露你的服务时。</li></ul></blockquote><ul><li><p><code>kubectl describe pod</code> 命令。它会告诉你 Pod 启动过程中发生的详细事件记录。</p></li><li><p>Deployment 要能够正常工作（特别是运行多个副本、进行滚动更新和自我修复），其底层的 Pod 必须通过类似 <code>generateName</code> 的机制来创建，以保证每个 Pod 名称的唯一性</p></li><li><p>在 Deployment（以及 ReplicaSet, StatefulSet, Job, CronJob 等这类控制器）的 Pod 模板（<code>spec.template</code>）中，<code>metadata.name</code> 这个字段是<strong>不能设置</strong>的。如果你尝试设置它，Kubernetes API Server 会拒绝你的请求。</p></li><li><p>一个 Deployment 实际上并不直接管理 Pod，它的工作流程是这样的：</p><ol><li><strong>Deployment</strong>: 你创建了一个 Deployment 资源，它的名称是固定的（比如 <code>nginx-deployment</code>）。这个 Deployment 负责管理“版本”。</li><li><strong>ReplicaSet</strong>: Deployment 会根据自己的 Pod 模板，创建一个 <strong>ReplicaSet</strong> 资源。这个 ReplicaSet 的名称是<strong>动态生成的</strong>，通常是 <code>[Deployment名称]-[Pod模板的哈希值]</code>，例如 <code>nginx-deployment-66b6c48dd5</code>。这个哈希值确保了每次你更新 Deployment 的 Pod 模板时（比如更换镜像版本），都会创建一个全新的、不同名称的 ReplicaSet。</li><li><strong>Pod</strong>: ReplicaSet 的任务很简单，就是确保有指定数量的、符合其模板的 Pod 正在运行。它会根据自己的名称作为<strong>前缀</strong>，去创建 Pod。所以，最终 Pod 的名称也是<strong>动态生成的</strong>，格式通常是 <code>[ReplicaSet名称]-[随机后缀]</code>，例如 <code>nginx-deployment-66b6c48dd5-x7p9m</code>。</li></ol></li><li><p>MetalLB (强烈推荐) 这是在自建集群（Bare-Metal）中实现 type: LoadBalancer 的最佳实践方案。MetalLB 是一个开源项目，它能为你的集群模拟云服务商的负载均衡器功能。</p></li><li><p>使用 kubectl explain 命令：这是一个非常有用的命令，可以帮助你了解任何 Kubernetes 资源的结构和字段。例如，如果你想知道 Deployment 的 apiVersion</p></li><li><p>一个完整的应用[系统]，一般只有一个type为loadbalancer的service?</p><blockquote><ul><li><p>对于一个完整的、现代化的应用系统（特别是基于微服务架构的 Web 应用），通常最佳实践就是只使用一个 Type=LoadBalancer 的 Service。标准的应用暴露架构：“LoadBalancer + Ingress Controller”</p></li><li><p>如果你的应用系统包含一些非 HTTP/HTTPS 的服务，比如：</p><ul><li>一个需要直接暴露给外部客户端的 数据库 (如 PostgreSQL)。</li><li>一个 MQTT 消息代理服务。</li><li>一个 SFTP 文件服务。</li></ul><p>这些服务工作在 TCP/UDP 层，Ingress Controller（通常为 HTTP 设计）无法处理。在这种情况下，为这些特定的服务再额外创建一个独立的 Type=LoadBalancer Service 是完全合理的。</p></li></ul></blockquote></li><li><p>怎么知道我的pod有没有启动成功？</p><blockquote><ol><li>宏观检查：<code>kubectl get pods</code></li><li>详细诊断：<code>kubectl describe pod [pod-name]</code></li><li>深入应用内部：<code>kubectl logs [pod-name]【可以用</code>--previous选择来查看上一次的日志，还可以用-f<code>】</code></li></ol></blockquote></li><li><p>在用k3d做测试时，集群节点 &quot;看&quot; 不到你本地机器上的 Docker 镜像</p><blockquote><ol><li><p>使用 <code>k3d image import</code> 命令</p><p><code>k</code>3d image import springboot3:v1.0.10 -c my-cluster``</p></li><li><p><strong>修改你的 Deployment YAML 文件</strong></p><p>imagePullPolicy: IfNotPresent # &lt;-- 关键！添加这一行</p></li></ol><p>在生产环境或更复杂的开发环境中，最佳实践是搭建一个镜像仓库（Registry），比如 Harbor、Nexus，或者直接使用 Docker Hub、阿里云 ACR 等。</p></blockquote></li><li><p>确认 Pod 内的应用是否真的正常工作</p><blockquote><p>运行以下命令，它会在你的本地 <code>8084</code> 端口和 Deployment 中的一个 Pod 的 <code>8084</code> 端口之间建立一个临时的、直接的通道：</p><div class="language-bash line-numbers-mode" data-highlighter="prismjs" data-ext="sh" data-title="sh"><pre><code><span class="line">kubectl port-forward deployment/springboot3-deployment <span class="token number">8084</span>:8084</span>
<span class="line"></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div></div></div><p>还可以在在集群内部测试 ：</p><p><strong>启动一个临时的测试 Pod</strong>：我们可以运行一个包含 <code>curl</code> 等网络工具的临时 Pod。</p><div class="language-bash line-numbers-mode" data-highlighter="prismjs" data-ext="sh" data-title="sh"><pre><code><span class="line"><span class="token comment"># 运行一个临时的 busybox Pod，并在结束后自动删除</span></span>
<span class="line">kubectl run my-test-pod <span class="token parameter variable">--image</span><span class="token operator">=</span>busybox <span class="token parameter variable">-it</span> <span class="token parameter variable">--rm</span> -- <span class="token function">sh</span></span>
<span class="line"><span class="token comment">## kubectl run my-debug-pod --image=curlimages/curl -i --tty --rm -- /bin/sh 这个也可以</span></span>
<span class="line"></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p><strong>在临时 Pod 内通过 Service 名称访问</strong>：Kubernetes 自带了 DNS 服务，你可以直接通过 Service 的名称来访问它。</p><div class="language-bash line-numbers-mode" data-highlighter="prismjs" data-ext="sh" data-title="sh"><pre><code><span class="line"><span class="token comment"># 假设你已经在 my-test-pod 的 shell 中</span></span>
<span class="line"><span class="token comment"># 语法: wget -qO- http://[service-name]:[service-port]</span></span>
<span class="line"><span class="token function">wget</span> -qO- http://springboot3-service:8084</span>
<span class="line"></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>如果返回了应用的正确响应，说明 Service 的服务发现和端口转发都是正常的。</p></blockquote></li><li><p>In cases when objects represent a physical entity, like a Node representing a physical host, when the host is re-created under the same name without deleting and re-creating the Node, Kubernetes treats the new host as the old one, which may lead to inconsistencies.</p><blockquote><ol><li><p>标记节点不可调度</p><p>kubectl cordon worker-01</p></li><li><p><strong>驱逐节点上的所有 Pod</strong></p><p>kubectl drain worker-01 --ignore-daemonsets</p></li><li><p>从 Kubernetes 中删除节点对象</p><p>kubectl delete node worker-01</p></li></ol></blockquote></li><li><p>The server may generate a name when generateName is provided instead of name in a resource create request. When generateName is used, the provided value is used as a name prefix, which server appends a generated suffix to.</p><blockquote><p>Kubernetes v1.31以后会重试8次以使生成唯一的名字</p></blockquote></li><li><p>什么时候会单独定义和使用 Pod</p><blockquote><p><strong>场景示例</strong>：你想测试一下集群内部的网络是否通畅，或者想看某个 <code>Service</code> 是否能被访问到。</p><p><strong>操作</strong>：你可以快速创建一个包含网络工具（如 <code>curl</code>, <code>ping</code>, <code>dig</code>）的 Pod，然后通过 <code>kubectl exec</code> 进入这个 Pod 进行调试。调试结束后，直接删除这个 Pod 即可，不留任何痕迹。</p><p><strong>示例 YAML (</strong><code>debug-pod.yaml</code><strong>)：</strong></p><div class="language-yaml line-numbers-mode" data-highlighter="prismjs" data-ext="yml" data-title="yml"><pre><code><span class="line"><span class="token key atrule">apiVersion</span><span class="token punctuation">:</span> v1</span>
<span class="line"><span class="token key atrule">kind</span><span class="token punctuation">:</span> Pod</span>
<span class="line"><span class="token key atrule">metadata</span><span class="token punctuation">:</span></span>
<span class="line">	<span class="token key atrule">name</span><span class="token punctuation">:</span> curl<span class="token punctuation">-</span>pod</span>
<span class="line">	<span class="token key atrule">spec</span><span class="token punctuation">:</span></span>
<span class="line">		<span class="token key atrule">containers</span><span class="token punctuation">:</span></span>
<span class="line">\<span class="token comment"># 我们用一个包含 curl 的镜像，并让它一直运行，以便我们能 exec 进去</span></span>
<span class="line">			<span class="token punctuation">-</span> <span class="token key atrule">name</span><span class="token punctuation">:</span> my<span class="token punctuation">-</span>curl</span>
<span class="line">              <span class="token key atrule">image</span><span class="token punctuation">:</span> curlimages/curl<span class="token punctuation">:</span>latest</span>
<span class="line">        <span class="token key atrule">command</span><span class="token punctuation">:</span> <span class="token punctuation">[</span><span class="token string">&quot;sleep&quot;</span><span class="token punctuation">,</span> <span class="token string">&quot;3600&quot;</span><span class="token punctuation">]</span> <span class="token comment"># 让容器保持运行，否则它会立即退出</span></span>
<span class="line"></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p><strong>使用命令</strong>:</p><div class="language-bash line-numbers-mode" data-highlighter="prismjs" data-ext="sh" data-title="sh"><pre><code><span class="line"><span class="token comment"># 创建 Pod</span></span>
<span class="line">kubectl apply <span class="token parameter variable">-f</span> debug-pod.yaml</span>
<span class="line"></span>
<span class="line"><span class="token comment"># 进入 Pod 内部执行命令</span></span>
<span class="line">kubectl <span class="token builtin class-name">exec</span> <span class="token parameter variable">-it</span> curl-pod -- <span class="token function">sh</span></span>
<span class="line"></span>
<span class="line"><span class="token comment"># (在 Pod 内部)</span></span>
<span class="line"><span class="token comment"># curl [your-service-name].[namespace].svc.cluster.local</span></span>
<span class="line"><span class="token comment"># exit</span></span>
<span class="line"></span>
<span class="line"><span class="token comment"># 调试完毕后删除 Pod</span></span>
<span class="line">kubectl delete pod curl-pod </span>
<span class="line"></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div></blockquote></li><li><p>Keep in mind that label Key must be unique for a given object</p></li><li><p>Labels are key/value pairs. Valid label keys have two segments: an optional prefix and name, separated by a slash (/).</p><blockquote><p>Valid label value:</p><ul><li>must be 63 characters or less (can be empty),</li><li>unless empty, must begin and end with an alphanumeric character (<code>[a-z0-9A-Z]</code>),</li><li>could contain dashes (<code>-</code>), underscores (<code>_</code>), dots (<code>.</code>), and alphanumerics between.</li></ul></blockquote></li><li><p>The API currently supports two types of selectors: equality-based and set-based.</p></li><li><p>If the prefix is omitted, the label Key is presumed to be private to the user. Automated system components (e.g. kube-scheduler, kube-controller-manager, kube-apiserver, kubectl, or other third-party automation) which add labels to end-user objects must specify a prefix.</p></li><li><p>the comma separator acts as a logical AND (&amp;&amp;) operator.</p></li><li><p>selector: { component: redis } 是旧版的、简洁的写法。</p><p>selector: { matchLabels: { component: redis } } 是新版的、更结构化、更推荐的写法。</p><p>Kubernetes API 在处理第一种写法时，会自动将其理解为第二种写法。</p></li><li><p>Newer resources, such as Job, Deployment, ReplicaSet, and DaemonSet, support set-based requirements as well.</p><blockquote><div class="language-yaml line-numbers-mode" data-highlighter="prismjs" data-ext="yml" data-title="yml"><pre><code><span class="line"><span class="token key atrule">selector</span><span class="token punctuation">:</span></span>
<span class="line">  <span class="token key atrule">matchLabels</span><span class="token punctuation">:</span></span>
<span class="line">    <span class="token key atrule">component</span><span class="token punctuation">:</span> redis</span>
<span class="line">  <span class="token key atrule">matchExpressions</span><span class="token punctuation">:</span></span>
<span class="line">    <span class="token punctuation">-</span> <span class="token punctuation">{</span> <span class="token key atrule">key</span><span class="token punctuation">:</span> tier<span class="token punctuation">,</span> <span class="token key atrule">operator</span><span class="token punctuation">:</span> In<span class="token punctuation">,</span> <span class="token key atrule">values</span><span class="token punctuation">:</span> <span class="token punctuation">[</span>cache<span class="token punctuation">]</span> <span class="token punctuation">}</span></span>
<span class="line">    <span class="token punctuation">-</span> <span class="token punctuation">{</span> <span class="token key atrule">key</span><span class="token punctuation">:</span> environment<span class="token punctuation">,</span> <span class="token key atrule">operator</span><span class="token punctuation">:</span> NotIn<span class="token punctuation">,</span> <span class="token key atrule">values</span><span class="token punctuation">:</span> <span class="token punctuation">[</span>dev<span class="token punctuation">]</span> <span class="token punctuation">}</span></span>
<span class="line"></span>
<span class="line"></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div></blockquote></li><li><p>set-based requirements 应用用引号包起来</p><blockquote><p>kubectl get pods -l &#39;environment in (production),tier in (frontend)&#39;</p></blockquote></li><li><p>kubectl get pods -l environment=production,tier=frontend</p></li><li><p>kubectl get pods -Lapp -Ltier -Lrole</p><blockquote><p>‘-L’ 参数不是过滤作用，而是在最终的查询结果中以列的形式显示</p></blockquote></li><li><p>更新label</p><blockquote><div class="language-bash line-numbers-mode" data-highlighter="prismjs" data-ext="sh" data-title="sh"><pre><code><span class="line">kubectl label pods <span class="token parameter variable">-l</span> <span class="token assign-left variable">app</span><span class="token operator">=</span>nginx <span class="token assign-left variable">tier</span><span class="token operator">=</span>fe</span>
<span class="line"></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div></div></div><p>This first filters all pods with the label &quot;app=nginx&quot;, and then labels them with the &quot;tier=fe&quot;。除了用-l app=nginx标签来过滤，还可以用pod的名字来过滤需要操作的pods</p><p>默认情况下，当已经存在tier标签时，不会更新成功。可以加入<code>kubectl label --overwrite pods</code>这个参数</p></blockquote></li><li><p>Names of resources need to be unique within a namespace, but not across namespaces.</p></li><li><p>Namespace-based scoping is applicable only for namespaced objects (e.g. Deployments, Services, etc.) and not for cluster-wide objects (e.g. StorageClass, Nodes, PersistentVolumes, etc.)</p></li><li><p>For a production cluster, consider not using the default namespace. Instead, make other namespaces and use those.</p></li><li><p>Kubernetes starts with four initial namespaces:</p><blockquote><ol><li>default</li><li>kube-node-lease</li><li>kube-public</li><li>kube-system</li></ol></blockquote></li><li><p>Avoid creating namespaces with the prefix kube-, since it is reserved for Kubernetes system namespaces.</p></li><li><p>kubectl get namespace</p></li><li><p>To set the namespace for a current request, use the --namespace flag.</p><blockquote><div class="language-bash line-numbers-mode" data-highlighter="prismjs" data-ext="sh" data-title="sh"><pre><code><span class="line">kubectl run nginx <span class="token parameter variable">--image</span><span class="token operator">=</span>nginx <span class="token parameter variable">--namespace</span><span class="token operator">=</span><span class="token punctuation">[</span>insert-namespace-name-here<span class="token punctuation">]</span></span>
<span class="line">kubectl get pods <span class="token parameter variable">--namespace</span><span class="token operator">=</span><span class="token punctuation">[</span>insert-namespace-name-here<span class="token punctuation">]</span></span>
<span class="line"></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div></div></div></blockquote></li><li><p>You can permanently save the namespace for all subsequent kubectl commands in that context.</p><blockquote><div class="language-bash line-numbers-mode" data-highlighter="prismjs" data-ext="sh" data-title="sh"><pre><code><span class="line">kubectl config set-context <span class="token parameter variable">--current</span> <span class="token parameter variable">--namespace</span><span class="token operator">=</span><span class="token punctuation">[</span>insert-namespace-name-here<span class="token punctuation">]</span></span>
<span class="line"><span class="token comment"># Validate it</span></span>
<span class="line">kubectl config view <span class="token parameter variable">--minify</span> <span class="token operator">|</span> <span class="token function">grep</span> namespace:</span>
<span class="line"></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div></blockquote></li><li><p>When you create a Service, it creates a corresponding DNS entry. This entry is of the form [service-name].[namespace-name].svc.cluster.local</p><blockquote><p>同一个namespace下的应用可以直接通过应用名解析到，而不同的namespace下则需要使用<strong>全限定域名。</strong> [service-name].[namespace-name].svc.cluster.local</p></blockquote></li><li><p>Not all objects are in a namespace</p><blockquote><p>However namespace resources are not themselves in a namespace. And low-level resources, such as nodes and persistentVolumes, are not in any namespace.</p><div class="language-bash line-numbers-mode" data-highlighter="prismjs" data-ext="sh" data-title="sh"><pre><code><span class="line"><span class="token comment"># In a namespace</span></span>
<span class="line">kubectl api-resources <span class="token parameter variable">--namespaced</span><span class="token operator">=</span>true</span>
<span class="line"></span>
<span class="line"><span class="token comment"># Not in a namespace</span></span>
<span class="line">kubectl api-resources <span class="token parameter variable">--namespaced</span><span class="token operator">=</span>false</span>
<span class="line"></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div></blockquote></li><li><p>The Kubernetes control plane sets an immutable label kubernetes.io/metadata.name on all namespaces. The value of the label is the namespace name</p><blockquote><p>kubectl describe namespaces kube-system</p></blockquote></li><li><p>The keys and the values in the map must be strings. In other words, you cannot use numeric, boolean, list or other types for either the keys or the values.</p></li><li><p>Annotations are key/value pairs. Valid annotation keys have two segments: an optional prefix and name, separated by a slash (/).</p><blockquote><p>The name segment is required and must be 63 characters or less, beginning and ending with an alphanumeric character (<code>[a-z0-9A-Z]</code>) with dashes (<code>-</code>), underscores (<code>_</code>), dots (<code>.</code>), and alphanumerics between.</p></blockquote></li><li><p>Field selectors are essentially resource filters. By default, no selectors/filters are applied, meaning that all resources of the specified type are selected. This makes the kubectl queries kubectl get pods and kubectl get pods --field-selector &quot;&quot; equivalent.</p></li><li><p>You can use the =, ==, and != operators with field selectors (= and == mean the same thing).</p><blockquote><p>kubectl get services --all-namespaces --field-selector metadata.namespace!=default</p></blockquote></li><li><p>As with label and other selectors, field selectors can be chained together as a comma-separated list.</p><blockquote><p>kubectl get pods --field-selector=status.phase!=Running,spec.restartPolicy=Always</p></blockquote></li><li><p>Finalizer 是一个存在于资源对象 metadata 中的字符串列表。</p></li><li><p>这个 Finalizer 确保了当你删除这个 Service 时，Kubernetes 会先调用云平台的 API 去删除那个真实的、会产生费用的负载均衡器，然后再删除 Service 对象本身。如果没有这个机制，你可能会留下很多无人管理的“僵尸”云资源。</p><blockquote><p><strong>Finalizer</strong>: <code>service.kubernetes.io/load-balancer-cleanup</code> (在一些云厂商的实现中)</p></blockquote></li><li><p>为什么资源会卡在 Terminating 状态？🚨 这是你在实践中一定会遇到的经典问题。当一个资源长时间处于 Terminating 状态时，几乎 100% 是 Finalizer 导致的。</p><blockquote><p><strong>原因</strong>：负责清理并移除那个 Finalizer 的控制器<strong>无法完成它的工作</strong>。</p></blockquote></li><li><p>Finalizers are namespaced keys that tell Kubernetes to wait until specific conditions are met before it fully deletes resources marked for deletion. Finalizers alert controllers to clean up resources the deleted object owned.</p><blockquote><p><strong>Marked for deletion (标记为删除)</strong>: 资源有了 <code>deletionTimestamp</code>，处于 <code>Terminating</code> 状态。它对外已经“死亡”（比如 Pod 不再接收流量），但它的“尸体”（在 etcd 中的记录）还在。</p><p><strong>Fully deleted (彻底删除)</strong>: 资源的记录从 etcd 中被彻底抹除，它不复存在了。</p><p><strong>Specific conditions are met (特定条件被满足)</strong>: 这个“特定条件”非常明确，<strong>指的就是</strong> <code>metadata.finalizers</code> <strong>列表变为空</strong>。</p><p>那么谁来清空这个列表呢？答案是<strong>控制器 (Controller)</strong>。</p><ul><li>每个 Finalizer 字符串都对应一个正在运行的控制器。</li><li>这个控制器一直在监控，当它发现自己负责的资源出现了 <code>deletionTimestamp</code> 时，它就知道该干活了（执行清理任务）。</li><li>清理任务完成后（比如云硬盘被删了，数据库备份好了），控制器就会发起一个 API 请求，把自己负责的那个 Finalizer 字符串从列表中<strong>移除</strong>。</li><li>当所有控制器都完成了自己的任务，<code>finalizers</code> 列表就变空了。</li></ul><p>它实际上是一个<strong>字符串</strong>。这些字符串存在于一个列表里，位置在 <code>metadata.finalizers</code></p><p>它们像带有名空间的键一样，是独一无二的标识符</p><p>简单来说：你可以把它理解为“带有唯一前缀的特殊标签”。</p><div class="language-yaml line-numbers-mode" data-highlighter="prismjs" data-ext="yml" data-title="yml"><pre><code><span class="line"><span class="token key atrule">metadata</span><span class="token punctuation">:</span></span>
<span class="line">  <span class="token key atrule">finalizers</span><span class="token punctuation">:</span></span>
<span class="line">  <span class="token punctuation">-</span> kubernetes.io/pv<span class="token punctuation">-</span>protection  <span class="token comment"># 一个遵循 &quot;namespaced key&quot; 格式的字符串</span></span>
<span class="line">  <span class="token punctuation">-</span> another.tool.com/do<span class="token punctuation">-</span>backup    <span class="token comment"># 另一个遵循同样格式的字符串</span></span>
<span class="line"></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div></blockquote></li><li><p>Custom finalizer names must be publicly qualified finalizer names, such as example.com/finalizer-name. Kubernetes enforces this format; the API server rejects writes to objects where the change does not use qualified finalizer names for any custom finalizer.</p></li><li><p>Dependent objects also have an ownerReferences.blockOwnerDeletion field that takes a boolean value and controls whether specific dependents can block garbage collection from deleting their owner object. Kubernetes automatically sets this field to true if a controller (for example, the Deployment controller) sets the value of the metadata.ownerReferences field. You can also set the value of the blockOwnerDeletion field manually to control which dependents block garbage collection.</p><blockquote><p>关系链: Deployment -&gt; ReplicaSet -&gt; Pod。</p><p>删除链: 删除 Deployment -&gt; 删除 ReplicaSet -&gt; 删除 Pod。</p><p>blockOwnerDeletion: true: 是一个 “刹车”。Dependent 对象对 Owner 说：“别删我老板，除非我先走！”</p><p>kubectl delete deployment 触发的是一个“有序解散”，而非“斩首行动【直接删除deployment】”</p></blockquote></li><li><p>In foreground deletion, it adds the foreground finalizer so that the controller must delete dependent resources that also have ownerReferences.blockOwnerDeletion=true before it deletes the owner.</p></li><li><p>kubectl delete deployment my-app --cascade=orphan</p><blockquote><p><strong>会发生什么？</strong></p><ol><li><code>Deployment</code> <strong>对象被立即删除</strong>：<code>my-app</code> 这个 <code>Deployment</code> 资源瞬间就消失了。</li><li><code>ReplicaSet</code> <strong>和</strong> <code>Pod</code> <strong>完好无损</strong>：你会惊讶地发现，<code>ReplicaSet</code> 和所有的 <code>Pod</code> 依然在运行！</li><li><code>ReplicaSet</code> <strong>成为孤儿</strong>：如果你查看那个幸存的 <code>ReplicaSet</code> 的 YAML (<code>kubectl get rs [rs-name] -o yaml</code>)，你会发现它 <code>metadata</code> 里的 <code>ownerReferences</code> 字段<strong>已经不见了</strong>。它不再属于任何人，变成了一个独立的、没人管理的 <code>ReplicaSet</code>。</li></ol></blockquote></li><li><p>Shared labels and annotations share a common prefix: app.kubernetes.io. Labels without a prefix are private to users. The shared prefix ensures that shared labels do not interfere with custom user labels.</p><blockquote><p><strong>Shared Labels</strong> 是一套 <strong>官方推荐的、标准化的标签</strong>。它们使用 <code>app.kubernetes.io/</code> 这个统一的前缀，目的是为了让不同的工具、团队和用户能够用一种通用的方式来描述和识别在 Kubernetes 中运行的应用程序</p></blockquote></li><li><p>The metadata is organized around the concept of an application. Kubernetes is not a platform as a service (PaaS) and doesn&#39;t have or enforce a formal notion of an application. Instead, applications are informal and described with metadata. The definition of what an application contains is loose.</p></li><li><p>There are two mechanisms that Kubernetes uses to publish these API specifications</p><blockquote><ol><li>The Discovery API</li><li>The Kubernetes OpenAPI Document</li></ol></blockquote></li><li><p>Pods that are part of a DaemonSet tolerate being run on an unschedulable Node. DaemonSets typically provide node-local services that should run on the Node even if it is being drained of workload applications.</p></li><li><blockquote><p>在 Kubernetes 中，这些“必须安装在每个节点上”的后台服务，就是通过 DaemonSet 来部署的。常见的例子有：日志收集器，节点监控器，网络插件，存储插件</p></blockquote></li><li><p>In case of a Node, it is implicitly assumed that an instance using the same name will have the same state (e.g. network settings, root disk contents) and attributes like node labels.</p><blockquote><p>这里的instance是指虚拟机或者物理机。 Kubernetes 认‘名’不认‘人’。它把节点名称当作身份证号。如果一个新人拿了旧人的身份证号来报到，系统会把他当成旧人，但这个新人的能力和背景（磁盘内容、硬件属性）是全新的。这种身份与实际能力的不匹配，正是很多诡异问题的根源。请务必确保在替换节点时，先‘注销’旧的身份信息（kubectl delete node），再让新人用自己的身份注册。</p></blockquote></li><li><p>Register the node with the given list of taints</p><blockquote><p>可以把 Taint (污点) 想象成节点（Node）上的一个“排斥标签”或者“谢绝入内”的牌子。 一旦一个节点被打上了某个 Taint，Kubernetes 的调度器（Scheduler）默认就不会把任何 Pod 调度到这个节点上。这就好像一个房间门口挂着“请勿打扰”的牌子，正常情况下，没有人会进去。</p></blockquote></li><li><p>执行这个命令，你会看到 kubectl 正在向 apiserver 发出一系列的 GET 请求来发现资源</p></li></ul><div class="language-bash line-numbers-mode" data-highlighter="prismjs" data-ext="sh" data-title="sh"><pre><code><span class="line">kubectl get pods <span class="token parameter variable">--v</span><span class="token operator">=</span><span class="token number">8</span></span>
<span class="line"></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div></div></div><ul><li>--api-group=&quot;&quot; 表示查询核心组</li></ul><div class="language-bash line-numbers-mode" data-highlighter="prismjs" data-ext="sh" data-title="sh"><pre><code><span class="line">kubectl api-resources --api-group<span class="token operator">=</span><span class="token string">&quot;&quot;</span></span>
<span class="line"></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div></div></div><ul><li><p>首先，我们必须明白 Discovery API 的目的。无论是 kubectl、Rancher UI 还是任何其他与 Kubernetes 集群交互的客户端，它们在执行操作之前，都需要先知道： “这个集群里有哪些 API Group？” (例如 apps, batch, networking.k8s.io 等)。“每个 Group 下有哪些版本？” (例如 apps group 下有 v1)“每个 Group/Version 下有哪些资源 (Resource)？” (例如 apps/v1 下有 deployments, statefulsets, daemonsets 等) “这些资源支持哪些操作 (Verb)？” (例如 deployments 支持 create, get, list, delete 等)</p></li><li><p>Unaggregated Discovery (非聚合发现) Unaggregated Discovery 指的是 单个 API 服务器自身 提供的、关于 它自己所能服务的 API 的发现信息。</p></li><li><p>Aggregated Discovery (聚合发现) Aggregated Discovery 正是 Kubernetes API Aggregation Layer (聚合层) 的强大之处。它提供了一个 统一的、聚合后 的视图。 当客户端（如 kubectl）查询主 kube-apiserver 的发现端点时，聚合层不仅会返回 kube-apiserver 自己的 API 信息，还会智能地将所有已注册的扩展 API 服务器（通过 APIService 对象注册）的发现信息也一并包含进来并返回。</p></li><li><p>Kubernetes offers stable support for aggregated discovery, publishing all resources supported by a cluster through two endpoints (/api and /apis).</p><blockquote><ul><li>/api: 列出核心 API Group (只有 v1)。</li><li>/apis: 列出所有非核心的 API Group (如 apps, batch, apiextensions.k8s.io 等)。 为什么会有两个端点： 最初的设计: 在 Kubernetes 的早期，所有的 API 资源对象（如 Pod, Service, Node, ReplicationController 等）都被放在一个没有名字的 API Group 里，这个 Group 就是我们所说的“核心组 (Core Group) ”。由于它没有名字，为了访问它，API Server 就提供了 /api/v1 这个特殊的端点。在当时，这就是 Kubernetes 的全部 API。 发现扩展性问题: 随着项目的发展，开发者们很快意识到，把所有东西都塞进一个没有分组的 API 里是无法扩展的。如果我想添加一组新的 API 用于处理“批处理任务”，或者另一组 API 用于处理“网络策略”，把它们都堆在核心组里会变得非常混乱。 “命名组”的诞生: 为了解决这个问题，Kubernetes 引入了“API Group（命名组）”的概念。这允许开发者根据功能领域将 API 资源进行逻辑分组。例如： apps 组：包含 Deployment, StatefulSet, DaemonSet 等。batch 组：包含 Job, CronJob 等。 networking.k8s.io 组：包含 Ingress, NetworkPolicy 等。 所有这些“命名组”的 API 都通过一个统一的前缀 /apis 来访问，例如 /apis/apps/v1，/apis/batch/v1。</li></ul></blockquote></li><li><p>Without indicating the resource type using the Accept header, the default response for the /api and /apis endpoint is an unaggregated discovery document.</p></li><li><p>the kubectl tool fetches and caches the API specification for enabling command-line completion and other features. The two supported mechanisms are as follows:</p><ul><li>Discovery API 就像是这本书的 “目录”。</li><li>OpenAPI Document 就像是这本书 “正文内容中所有名词的详细解释和语法结构说明”</li></ul></li><li><p>这是最简单、最安全，也是最推荐的本地调试方法。<code>kubectl proxy</code> 命令会在你的本地机器上启动一个代理服务器，它负责将你的本地请求安全地转发到 k3d 集群内部的 API Server。</p></li></ul></div><!--[--><!--]--></div><footer class="vp-page-meta"><!----><div class="vp-meta-item git-info"><div class="vp-meta-item last-updated"><span class="meta-item-label">Last Updated: </span><!----></div><div class="vp-meta-item contributors"><span class="meta-item-label">Contributors: </span><span class="meta-item-info"><!--[--><!--[--><span class="contributor" title="email: 1308811723@qq.com">RuanCong</span><!--[-->, <!--]--><!--]--><!--[--><span class="contributor" title="email: ruancong130@gmail.com">Leite-home</span><!----><!--]--><!--]--></span></div></div></footer><!----><!--[--><!--]--></main><!--]--></div><!--[--><!----><!--]--><!--]--></div>
    <script type="module" src="/assets/app-DXTNhLx0.js" defer></script>
  </body>
</html>
